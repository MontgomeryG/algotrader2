{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ELEMENTARY TRADING BOT\n",
    "\n",
    "The below is a start at using 3 machine learning models to create long/short signals in instances where the stock trades in a range. We will look to employ the algorithm during instances defined with the following characteristics:\n",
    "- Large-cap stocks (they tend to offer ranges intraday that \"scalpers\" take advantage of. I'm willing to bet an algo can learn how to scalp like those traders or even better.)\n",
    "- During times of low volatility. Low Volatility is essentially what we mean when we say, \"the stock is trading in a range\"; when the price action of a stock can be considered \"range-bound\".  This is typically in the middle of the day when there is less volume in the markets. We can visualize the average volume given time of day later on in this project. \n",
    "\n",
    "We will start with the above, keeing it simple.\n",
    "\n",
    "\n",
    "Our next step is to choose the variables that we will feed the algorithm. Remember that these variables will be based on a stock's Open Low High and Close (OHLC), and Volume, for now..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TO--DO\n",
    "Now we determine the stocks of which we'd like to pull the OHLC data.\n",
    "Let's go with all of the stocks in the NQ and the ES. This should serve as a nice basis for how the type of stocks that we want to deploy our algorithm onto move; ***mega-cap stocks that offer range-bound trading during periods of low volatility.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting a list of the stocks in the NQ and ES onto a dataframe. \n",
    "\n",
    "Let's start with the NQ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n  var py_version = '3.2.1'.replace('rc', '-rc.').replace('.dev', '-dev.');\n  var is_dev = py_version.indexOf(\"+\") !== -1 || py_version.indexOf(\"-\") !== -1;\n  var reloading = false;\n  var Bokeh = root.Bokeh;\n  var bokeh_loaded = Bokeh != null && (Bokeh.version === py_version || (Bokeh.versions !== undefined && Bokeh.versions.has(py_version)));\n\n  if (typeof (root._bokeh_timeout) === \"undefined\" || force) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks;\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, js_modules, js_exports, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n    if (js_modules == null) js_modules = [];\n    if (js_exports == null) js_exports = {};\n\n    root._bokeh_onload_callbacks.push(callback);\n\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls.length === 0 && js_modules.length === 0 && Object.keys(js_exports).length === 0) {\n      run_callbacks();\n      return null;\n    }\n    if (!reloading) {\n      console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    }\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n    window._bokeh_on_load = on_load\n\n    function on_error() {\n      console.error(\"failed to load \" + url);\n    }\n\n    var skip = [];\n    if (window.requirejs) {\n      window.requirejs.config({'packages': {}, 'paths': {'jspanel': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/jspanel', 'jspanel-modal': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/modal/jspanel.modal', 'jspanel-tooltip': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/tooltip/jspanel.tooltip', 'jspanel-hint': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/hint/jspanel.hint', 'jspanel-layout': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/layout/jspanel.layout', 'jspanel-contextmenu': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/contextmenu/jspanel.contextmenu', 'jspanel-dock': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/dock/jspanel.dock', 'gridstack': 'https://cdn.jsdelivr.net/npm/gridstack@7.2.3/dist/gridstack-all', 'notyf': 'https://cdn.jsdelivr.net/npm/notyf@3/notyf.min'}, 'shim': {'jspanel': {'exports': 'jsPanel'}, 'gridstack': {'exports': 'GridStack'}}});\n      require([\"jspanel\"], function(jsPanel) {\n\twindow.jsPanel = jsPanel\n\ton_load()\n      })\n      require([\"jspanel-modal\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-tooltip\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-hint\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-layout\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-contextmenu\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-dock\"], function() {\n\ton_load()\n      })\n      require([\"gridstack\"], function(GridStack) {\n\twindow.GridStack = GridStack\n\ton_load()\n      })\n      require([\"notyf\"], function() {\n\ton_load()\n      })\n      root._bokeh_is_loading = css_urls.length + 9;\n    } else {\n      root._bokeh_is_loading = css_urls.length + js_urls.length + js_modules.length + Object.keys(js_exports).length;\n    }\n\n    var existing_stylesheets = []\n    var links = document.getElementsByTagName('link')\n    for (var i = 0; i < links.length; i++) {\n      var link = links[i]\n      if (link.href != null) {\n\texisting_stylesheets.push(link.href)\n      }\n    }\n    for (var i = 0; i < css_urls.length; i++) {\n      var url = css_urls[i];\n      if (existing_stylesheets.indexOf(url) !== -1) {\n\ton_load()\n\tcontinue;\n      }\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }    if (((window['jsPanel'] !== undefined) && (!(window['jsPanel'] instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdn.holoviz.org/panel/1.2.3/dist/bundled/floatpanel/jspanel4@4.12.0/dist/jspanel.js', 'https://cdn.holoviz.org/panel/1.2.3/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/modal/jspanel.modal.js', 'https://cdn.holoviz.org/panel/1.2.3/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/tooltip/jspanel.tooltip.js', 'https://cdn.holoviz.org/panel/1.2.3/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/hint/jspanel.hint.js', 'https://cdn.holoviz.org/panel/1.2.3/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/layout/jspanel.layout.js', 'https://cdn.holoviz.org/panel/1.2.3/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/contextmenu/jspanel.contextmenu.js', 'https://cdn.holoviz.org/panel/1.2.3/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/dock/jspanel.dock.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(urls[i])\n      }\n    }    if (((window['GridStack'] !== undefined) && (!(window['GridStack'] instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdn.holoviz.org/panel/1.2.3/dist/bundled/gridstack/gridstack@7.2.3/dist/gridstack-all.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(urls[i])\n      }\n    }    if (((window['Notyf'] !== undefined) && (!(window['Notyf'] instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdn.holoviz.org/panel/1.2.3/dist/bundled/notificationarea/notyf@3/notyf.min.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(urls[i])\n      }\n    }    var existing_scripts = []\n    var scripts = document.getElementsByTagName('script')\n    for (var i = 0; i < scripts.length; i++) {\n      var script = scripts[i]\n      if (script.src != null) {\n\texisting_scripts.push(script.src)\n      }\n    }\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      if (skip.indexOf(url) !== -1 || existing_scripts.indexOf(url) !== -1) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (var i = 0; i < js_modules.length; i++) {\n      var url = js_modules[i];\n      if (skip.indexOf(url) !== -1 || existing_scripts.indexOf(url) !== -1) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (const name in js_exports) {\n      var url = js_exports[name];\n      if (skip.indexOf(url) >= 0 || root[name] != null) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onerror = on_error;\n      element.async = false;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      element.textContent = `\n      import ${name} from \"${url}\"\n      window.${name} = ${name}\n      window._bokeh_on_load()\n      `\n      document.head.appendChild(element);\n    }\n    if (!js_urls.length && !js_modules.length) {\n      on_load()\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  var js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-3.2.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.2.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.2.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.2.1.min.js\", \"https://cdn.holoviz.org/panel/1.2.3/dist/panel.min.js\"];\n  var js_modules = [];\n  var js_exports = {};\n  var css_urls = [];\n  var inline_js = [    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {} // ensure no trailing comma for IE\n  ];\n\n  function run_inline_js() {\n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (var i = 0; i < inline_js.length; i++) {\n        inline_js[i].call(root, root.Bokeh);\n      }\n      // Cache old bokeh versions\n      if (Bokeh != undefined && !reloading) {\n\tvar NewBokeh = root.Bokeh;\n\tif (Bokeh.versions === undefined) {\n\t  Bokeh.versions = new Map();\n\t}\n\tif (NewBokeh.version !== Bokeh.version) {\n\t  Bokeh.versions.set(NewBokeh.version, NewBokeh)\n\t}\n\troot.Bokeh = Bokeh;\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    }\n    root._bokeh_is_initializing = false\n  }\n\n  function load_or_wait() {\n    // Implement a backoff loop that tries to ensure we do not load multiple\n    // versions of Bokeh and its dependencies at the same time.\n    // In recent versions we use the root._bokeh_is_initializing flag\n    // to determine whether there is an ongoing attempt to initialize\n    // bokeh, however for backward compatibility we also try to ensure\n    // that we do not start loading a newer (Panel>=1.0 and Bokeh>3) version\n    // before older versions are fully initialized.\n    if (root._bokeh_is_initializing && Date.now() > root._bokeh_timeout) {\n      root._bokeh_is_initializing = false;\n      root._bokeh_onload_callbacks = undefined;\n      console.log(\"Bokeh: BokehJS was loaded multiple times but one version failed to initialize.\");\n      load_or_wait();\n    } else if (root._bokeh_is_initializing || (typeof root._bokeh_is_initializing === \"undefined\" && root._bokeh_onload_callbacks !== undefined)) {\n      setTimeout(load_or_wait, 100);\n    } else {\n      Bokeh = root.Bokeh;\n      bokeh_loaded = Bokeh != null && (Bokeh.version === py_version || (Bokeh.versions !== undefined && Bokeh.versions.has(py_version)));\n      root._bokeh_is_initializing = true\n      root._bokeh_onload_callbacks = []\n      if (!reloading && (!bokeh_loaded || is_dev)) {\n\troot.Bokeh = undefined;\n      }\n      load_libs(css_urls, js_urls, js_modules, js_exports, function() {\n\tconsole.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n\trun_inline_js();\n      });\n    }\n  }\n  // Give older versions of the autoload script a head-start to ensure\n  // they initialize before we start loading newer version.\n  setTimeout(load_or_wait, 100)\n}(window));",
      "application/vnd.holoviews_load.v0+json": ""
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "\nif ((window.PyViz === undefined) || (window.PyViz instanceof HTMLElement)) {\n  window.PyViz = {comms: {}, comm_status:{}, kernels:{}, receivers: {}, plot_index: []}\n}\n\n\n    function JupyterCommManager() {\n    }\n\n    JupyterCommManager.prototype.register_target = function(plot_id, comm_id, msg_handler) {\n      if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        comm_manager.register_target(comm_id, function(comm) {\n          comm.on_msg(msg_handler);\n        });\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        window.PyViz.kernels[plot_id].registerCommTarget(comm_id, function(comm) {\n          comm.onMsg = msg_handler;\n        });\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        google.colab.kernel.comms.registerTarget(comm_id, (comm) => {\n          var messages = comm.messages[Symbol.asyncIterator]();\n          function processIteratorResult(result) {\n            var message = result.value;\n            console.log(message)\n            var content = {data: message.data, comm_id};\n            var buffers = []\n            for (var buffer of message.buffers || []) {\n              buffers.push(new DataView(buffer))\n            }\n            var metadata = message.metadata || {};\n            var msg = {content, buffers, metadata}\n            msg_handler(msg);\n            return messages.next().then(processIteratorResult);\n          }\n          return messages.next().then(processIteratorResult);\n        })\n      }\n    }\n\n    JupyterCommManager.prototype.get_client_comm = function(plot_id, comm_id, msg_handler) {\n      if (comm_id in window.PyViz.comms) {\n        return window.PyViz.comms[comm_id];\n      } else if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        var comm = comm_manager.new_comm(comm_id, {}, {}, {}, comm_id);\n        if (msg_handler) {\n          comm.on_msg(msg_handler);\n        }\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        var comm = window.PyViz.kernels[plot_id].connectToComm(comm_id);\n        comm.open();\n        if (msg_handler) {\n          comm.onMsg = msg_handler;\n        }\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        var comm_promise = google.colab.kernel.comms.open(comm_id)\n        comm_promise.then((comm) => {\n          window.PyViz.comms[comm_id] = comm;\n          if (msg_handler) {\n            var messages = comm.messages[Symbol.asyncIterator]();\n            function processIteratorResult(result) {\n              var message = result.value;\n              var content = {data: message.data};\n              var metadata = message.metadata || {comm_id};\n              var msg = {content, metadata}\n              msg_handler(msg);\n              return messages.next().then(processIteratorResult);\n            }\n            return messages.next().then(processIteratorResult);\n          }\n        }) \n        var sendClosure = (data, metadata, buffers, disposeOnDone) => {\n          return comm_promise.then((comm) => {\n            comm.send(data, metadata, buffers, disposeOnDone);\n          });\n        };\n        var comm = {\n          send: sendClosure\n        };\n      }\n      window.PyViz.comms[comm_id] = comm;\n      return comm;\n    }\n    window.PyViz.comm_manager = new JupyterCommManager();\n    \n\n\nvar JS_MIME_TYPE = 'application/javascript';\nvar HTML_MIME_TYPE = 'text/html';\nvar EXEC_MIME_TYPE = 'application/vnd.holoviews_exec.v0+json';\nvar CLASS_NAME = 'output';\n\n/**\n * Render data to the DOM node\n */\nfunction render(props, node) {\n  var div = document.createElement(\"div\");\n  var script = document.createElement(\"script\");\n  node.appendChild(div);\n  node.appendChild(script);\n}\n\n/**\n * Handle when a new output is added\n */\nfunction handle_add_output(event, handle) {\n  var output_area = handle.output_area;\n  var output = handle.output;\n  if ((output.data == undefined) || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n    return\n  }\n  var id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n  var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n  if (id !== undefined) {\n    var nchildren = toinsert.length;\n    var html_node = toinsert[nchildren-1].children[0];\n    html_node.innerHTML = output.data[HTML_MIME_TYPE];\n    var scripts = [];\n    var nodelist = html_node.querySelectorAll(\"script\");\n    for (var i in nodelist) {\n      if (nodelist.hasOwnProperty(i)) {\n        scripts.push(nodelist[i])\n      }\n    }\n\n    scripts.forEach( function (oldScript) {\n      var newScript = document.createElement(\"script\");\n      var attrs = [];\n      var nodemap = oldScript.attributes;\n      for (var j in nodemap) {\n        if (nodemap.hasOwnProperty(j)) {\n          attrs.push(nodemap[j])\n        }\n      }\n      attrs.forEach(function(attr) { newScript.setAttribute(attr.name, attr.value) });\n      newScript.appendChild(document.createTextNode(oldScript.innerHTML));\n      oldScript.parentNode.replaceChild(newScript, oldScript);\n    });\n    if (JS_MIME_TYPE in output.data) {\n      toinsert[nchildren-1].children[1].textContent = output.data[JS_MIME_TYPE];\n    }\n    output_area._hv_plot_id = id;\n    if ((window.Bokeh !== undefined) && (id in Bokeh.index)) {\n      window.PyViz.plot_index[id] = Bokeh.index[id];\n    } else {\n      window.PyViz.plot_index[id] = null;\n    }\n  } else if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n    var bk_div = document.createElement(\"div\");\n    bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n    var script_attrs = bk_div.children[0].attributes;\n    for (var i = 0; i < script_attrs.length; i++) {\n      toinsert[toinsert.length - 1].childNodes[1].setAttribute(script_attrs[i].name, script_attrs[i].value);\n    }\n    // store reference to server id on output_area\n    output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n  }\n}\n\n/**\n * Handle when an output is cleared or removed\n */\nfunction handle_clear_output(event, handle) {\n  var id = handle.cell.output_area._hv_plot_id;\n  var server_id = handle.cell.output_area._bokeh_server_id;\n  if (((id === undefined) || !(id in PyViz.plot_index)) && (server_id !== undefined)) { return; }\n  var comm = window.PyViz.comm_manager.get_client_comm(\"hv-extension-comm\", \"hv-extension-comm\", function () {});\n  if (server_id !== null) {\n    comm.send({event_type: 'server_delete', 'id': server_id});\n    return;\n  } else if (comm !== null) {\n    comm.send({event_type: 'delete', 'id': id});\n  }\n  delete PyViz.plot_index[id];\n  if ((window.Bokeh !== undefined) & (id in window.Bokeh.index)) {\n    var doc = window.Bokeh.index[id].model.document\n    doc.clear();\n    const i = window.Bokeh.documents.indexOf(doc);\n    if (i > -1) {\n      window.Bokeh.documents.splice(i, 1);\n    }\n  }\n}\n\n/**\n * Handle kernel restart event\n */\nfunction handle_kernel_cleanup(event, handle) {\n  delete PyViz.comms[\"hv-extension-comm\"];\n  window.PyViz.plot_index = {}\n}\n\n/**\n * Handle update_display_data messages\n */\nfunction handle_update_output(event, handle) {\n  handle_clear_output(event, {cell: {output_area: handle.output_area}})\n  handle_add_output(event, handle)\n}\n\nfunction register_renderer(events, OutputArea) {\n  function append_mime(data, metadata, element) {\n    // create a DOM node to render to\n    var toinsert = this.create_output_subarea(\n    metadata,\n    CLASS_NAME,\n    EXEC_MIME_TYPE\n    );\n    this.keyboard_manager.register_events(toinsert);\n    // Render to node\n    var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n    render(props, toinsert[0]);\n    element.append(toinsert);\n    return toinsert\n  }\n\n  events.on('output_added.OutputArea', handle_add_output);\n  events.on('output_updated.OutputArea', handle_update_output);\n  events.on('clear_output.CodeCell', handle_clear_output);\n  events.on('delete.Cell', handle_clear_output);\n  events.on('kernel_ready.Kernel', handle_kernel_cleanup);\n\n  OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n    safe: true,\n    index: 0\n  });\n}\n\nif (window.Jupyter !== undefined) {\n  try {\n    var events = require('base/js/events');\n    var OutputArea = require('notebook/js/outputarea').OutputArea;\n    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n      register_renderer(events, OutputArea);\n    }\n  } catch(err) {\n  }\n}\n",
      "application/vnd.holoviews_load.v0+json": ""
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>*[data-root-id],\n",
       "*[data-root-id] > * {\n",
       "  box-sizing: border-box;\n",
       "  font-family: var(--jp-ui-font-family);\n",
       "  font-size: var(--jp-ui-font-size1);\n",
       "  color: var(--vscode-editor-foreground, var(--jp-ui-font-color1));\n",
       "}\n",
       "\n",
       "/* Override VSCode background color */\n",
       ".cell-output-ipywidget-background:has(\n",
       "    > .cell-output-ipywidget-background > .lm-Widget > *[data-root-id]\n",
       "  ),\n",
       ".cell-output-ipywidget-background:has(> .lm-Widget > *[data-root-id]) {\n",
       "  background-color: transparent !important;\n",
       "}\n",
       "</style>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import the required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import hvplot.pandas\n",
    "from pathlib import Path\n",
    "from finta import TA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Read csv, take a look\n",
    "# nq_df = pd.read_csv((\"../algotrader2/resources/nq_stocks.csv\"))\n",
    "# nq_df.head()\n",
    "\n",
    "# COMMENTING OUT NOW, We will do this later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Do the same for the snp 500 symbols\n",
    "# snp_df = pd.read_csv((\"../algotrader2/resources/snp_stocks.csv\"))\n",
    "# snp_df.head()\n",
    "\n",
    "# COMMENTING OUT NOW, We will do this later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save the symbols from each df\n",
    "# nq_symbols_df = nq_df[\"Symbol\"]\n",
    "# snp_symbols_df = snp_df[\"Symbol\"]\n",
    "\n",
    "# # Put dfs together\n",
    "# snp_nq_symbols_df = pd.concat([nq_symbols_df, snp_symbols_df], axis=0)\n",
    "\n",
    "# # Drop duplicates\n",
    "# snp_nq_symbols_df.drop_duplicates(inplace=True)\n",
    "\n",
    "# # View\n",
    "# snp_nq_symbols_df\n",
    "\n",
    "# COMMENTING OUT NOW, We will do this later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Convert symbols to a list so that we can feed it into our Alpaca API.\n",
    "# # Alpaca is where we will access the historical OHLC data needed.\n",
    "\n",
    "# nq_snp_symbols_list = snp_nq_symbols_df.tolist()\n",
    "\n",
    "# len(nq_snp_symbols_list)\n",
    "\n",
    "# COMMENTING OUT NOW, We will do this later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # THE FOLLOWING IS WHEN WE CONTINUE WITH MANY STOCKS...\n",
    "# # THE FOLLOWING NEEDS TO BE ITERATED\n",
    "\n",
    "# # Rearrange df\n",
    "# # Separate ticker data\n",
    "\n",
    "# # WE'LL HAVE TO iterate the below for all stocks in both the SPY and NQ\n",
    "\n",
    "# AAPL = aapl_msft_df[aapl_msft_df['symbol']=='AAPL'].drop('symbol', axis=1)\n",
    "# MSFT = aapl_msft_df[aapl_msft_df['symbol']=='MSFT'].drop('symbol', axis=1)\n",
    "\n",
    "# AAPL.sort_index(inplace=True)\n",
    "# MSFT.sort_index(inplace=True)\n",
    "\n",
    "# # Concatenate the ticker DataFrames\n",
    "# am_df = pd.concat([AAPL, MSFT],axis=1, keys=['AAPL','MSFT'])\n",
    "\n",
    "\n",
    "# am_df\n",
    "\n",
    "\n",
    "# # FEATURE CREATION WITH TWO stocks... this is for LATER USE\n",
    "\n",
    "# # Generate returns from close column with pct_change\n",
    "\n",
    "# # WILL NEED TO INTERATE\n",
    "# am_df[(\"AAPL\",\"actual_returns\")] = am_df[(\"AAPL\",\"close\")].pct_change()\n",
    "# am_df[(\"MSFT\",\"actual_returns\")] = am_df[(\"MSFT\",\"close\")].pct_change()\n",
    "\n",
    "# # Drop NaN\n",
    "# am_df = am_df.dropna()\n",
    "\n",
    "# # Simple Moving Averages\n",
    "# am_df[(\"AAPL\",\"AAPL_SMA5\")] = TA.SMA(am_df[\"AAPL\"],5)\n",
    "# am_df[(\"AAPL\",\"AAPL_SMA10\")] = TA.SMA(am_df[\"AAPL\"],10)\n",
    "\n",
    "# am_df[(\"MSFT\",\"MSFT_SMA5\")] = TA.SMA(am_df[\"MSFT\"],5)\n",
    "# am_df[(\"MSFT\",\"MSFT_SMA10\")] = TA.SMA(am_df[\"MSFT\"],10)\n",
    "\n",
    "# # Exponential Moving Averages\n",
    "# am_df[(\"AAPL\",\"AAPL_EMA3\")] = TA.EMA(am_df[\"AAPL\"],3)\n",
    "\n",
    "# am_df[(\"MSFT\",\"MSFT_EMA3\")] = TA.EMA(am_df[\"MSFT\"],3)\n",
    "\n",
    "# # NEEDS TO BE ITERATED!!\n",
    "\n",
    "\n",
    "# # Create a df with all the indicators for both AAPL and MSFT\n",
    "# aapl_indicator_df = am_df[\"AAPL\"].drop([\"actual_returns\"], axis=1)\n",
    "# msft_indicator_df = am_df[\"MSFT\"].drop([\"actual_returns\"], axis=1)\n",
    "\n",
    "# # Save the signal column as our 'y'\n",
    "# y=am_df[\"AAPL\"][\"signal\"]\n",
    "\n",
    "# display(aapl_indicator_df.head())\n",
    "# display(aapl_indicator_df.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay. Now let's set up our alpaca API to get the OHLC data.\n",
    "\n",
    "\n",
    "### Alpaca API for Historical OHLC Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports for Alpaca API, .env files, requests\n",
    "import os\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "import alpaca_trade_api as tradeapi\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load .env enviroment variables\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpaca Key type: <class 'str'>\n",
      "Alpaca Secret Key type: <class 'str'>\n"
     ]
    }
   ],
   "source": [
    "# Set Alpaca API key and secret\n",
    "alpaca_api_key = os.getenv(\"ALPACA_API_KEY\")\n",
    "alpaca_secret_key = os.getenv(\"ALPACA_SECRET_KEY\")\n",
    "\n",
    "# Verify that Alpaca key and secret were correctly loaded\n",
    "print(f\"Alpaca Key type: {type(alpaca_api_key)}\")\n",
    "print(f\"Alpaca Secret Key type: {type(alpaca_secret_key)}\")\n",
    "\n",
    "# Create the Alpaca API object\n",
    "alpaca = tradeapi.REST(\n",
    "    alpaca_api_key,\n",
    "    alpaca_secret_key,\n",
    "    api_version=\"v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set start and end dates and specify isoformat\n",
    "# We will start off with on week in the middle of November of this year, 2023.\n",
    "\n",
    "start_date = pd.Timestamp(\"2023-01-01\", tz=\"America/New_York\").isoformat()\n",
    "end_date = pd.Timestamp(\"2024-01-17\", tz=\"America/New_York\").isoformat()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the tickers\n",
    "# Test with one for now.\n",
    "# Later, this is where we will feed in our list of nq/es stocks we created above\n",
    "tickers = [\"AAPL\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set timeframe for Alpaca API\n",
    "timeframe = \"1Min\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get historical OHLC data for AAPL\n",
    "aapl_df = alpaca.get_bars(\n",
    "    tickers,\n",
    "    timeframe,\n",
    "    start = start_date,\n",
    "    end = end_date\n",
    ").df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>close</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>trade_count</th>\n",
       "      <th>open</th>\n",
       "      <th>volume</th>\n",
       "      <th>vwap</th>\n",
       "      <th>symbol</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-01-03 09:00:00+00:00</th>\n",
       "      <td>131.00</td>\n",
       "      <td>131.00</td>\n",
       "      <td>130.28</td>\n",
       "      <td>208</td>\n",
       "      <td>130.28</td>\n",
       "      <td>8174</td>\n",
       "      <td>130.854120</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-03 09:01:00+00:00</th>\n",
       "      <td>131.10</td>\n",
       "      <td>131.17</td>\n",
       "      <td>130.87</td>\n",
       "      <td>157</td>\n",
       "      <td>130.87</td>\n",
       "      <td>8820</td>\n",
       "      <td>130.955243</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-03 09:02:00+00:00</th>\n",
       "      <td>131.17</td>\n",
       "      <td>131.24</td>\n",
       "      <td>131.17</td>\n",
       "      <td>53</td>\n",
       "      <td>131.18</td>\n",
       "      <td>2112</td>\n",
       "      <td>131.208769</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-03 09:03:00+00:00</th>\n",
       "      <td>131.28</td>\n",
       "      <td>131.29</td>\n",
       "      <td>131.19</td>\n",
       "      <td>90</td>\n",
       "      <td>131.19</td>\n",
       "      <td>3888</td>\n",
       "      <td>131.220790</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-03 09:04:00+00:00</th>\n",
       "      <td>131.46</td>\n",
       "      <td>131.46</td>\n",
       "      <td>131.28</td>\n",
       "      <td>88</td>\n",
       "      <td>131.28</td>\n",
       "      <td>5984</td>\n",
       "      <td>131.327899</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-17 00:55:00+00:00</th>\n",
       "      <td>183.00</td>\n",
       "      <td>183.03</td>\n",
       "      <td>183.00</td>\n",
       "      <td>45</td>\n",
       "      <td>183.03</td>\n",
       "      <td>1224</td>\n",
       "      <td>183.014261</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-17 00:56:00+00:00</th>\n",
       "      <td>183.00</td>\n",
       "      <td>183.01</td>\n",
       "      <td>183.00</td>\n",
       "      <td>69</td>\n",
       "      <td>183.01</td>\n",
       "      <td>4641</td>\n",
       "      <td>183.001462</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-17 00:57:00+00:00</th>\n",
       "      <td>183.01</td>\n",
       "      <td>183.04</td>\n",
       "      <td>183.01</td>\n",
       "      <td>21</td>\n",
       "      <td>183.04</td>\n",
       "      <td>958</td>\n",
       "      <td>183.030350</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-17 00:58:00+00:00</th>\n",
       "      <td>183.05</td>\n",
       "      <td>183.05</td>\n",
       "      <td>183.04</td>\n",
       "      <td>21</td>\n",
       "      <td>183.04</td>\n",
       "      <td>671</td>\n",
       "      <td>183.043748</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-17 00:59:00+00:00</th>\n",
       "      <td>183.04</td>\n",
       "      <td>183.04</td>\n",
       "      <td>183.04</td>\n",
       "      <td>36</td>\n",
       "      <td>183.04</td>\n",
       "      <td>1574</td>\n",
       "      <td>183.043148</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>194711 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            close    high     low  trade_count    open  \\\n",
       "timestamp                                                                \n",
       "2023-01-03 09:00:00+00:00  131.00  131.00  130.28          208  130.28   \n",
       "2023-01-03 09:01:00+00:00  131.10  131.17  130.87          157  130.87   \n",
       "2023-01-03 09:02:00+00:00  131.17  131.24  131.17           53  131.18   \n",
       "2023-01-03 09:03:00+00:00  131.28  131.29  131.19           90  131.19   \n",
       "2023-01-03 09:04:00+00:00  131.46  131.46  131.28           88  131.28   \n",
       "...                           ...     ...     ...          ...     ...   \n",
       "2024-01-17 00:55:00+00:00  183.00  183.03  183.00           45  183.03   \n",
       "2024-01-17 00:56:00+00:00  183.00  183.01  183.00           69  183.01   \n",
       "2024-01-17 00:57:00+00:00  183.01  183.04  183.01           21  183.04   \n",
       "2024-01-17 00:58:00+00:00  183.05  183.05  183.04           21  183.04   \n",
       "2024-01-17 00:59:00+00:00  183.04  183.04  183.04           36  183.04   \n",
       "\n",
       "                           volume        vwap symbol  \n",
       "timestamp                                             \n",
       "2023-01-03 09:00:00+00:00    8174  130.854120   AAPL  \n",
       "2023-01-03 09:01:00+00:00    8820  130.955243   AAPL  \n",
       "2023-01-03 09:02:00+00:00    2112  131.208769   AAPL  \n",
       "2023-01-03 09:03:00+00:00    3888  131.220790   AAPL  \n",
       "2023-01-03 09:04:00+00:00    5984  131.327899   AAPL  \n",
       "...                           ...         ...    ...  \n",
       "2024-01-17 00:55:00+00:00    1224  183.014261   AAPL  \n",
       "2024-01-17 00:56:00+00:00    4641  183.001462   AAPL  \n",
       "2024-01-17 00:57:00+00:00     958  183.030350   AAPL  \n",
       "2024-01-17 00:58:00+00:00     671  183.043748   AAPL  \n",
       "2024-01-17 00:59:00+00:00    1574  183.043148   AAPL  \n",
       "\n",
       "[194711 rows x 8 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display sample data\n",
    "aapl_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FOR NOW, we will not include pre-market/after-hours action, but WE WILL in the future.\n",
    "\n",
    "Now we clean up the AAPL and MSFT dfs we created; put them together. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate ticker data\n",
    "AAPL = aapl_df[aapl_df['symbol']=='AAPL'].drop('symbol', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>close</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>trade_count</th>\n",
       "      <th>open</th>\n",
       "      <th>volume</th>\n",
       "      <th>vwap</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-01-03 09:00:00+00:00</th>\n",
       "      <td>131.00</td>\n",
       "      <td>131.00</td>\n",
       "      <td>130.28</td>\n",
       "      <td>208</td>\n",
       "      <td>130.28</td>\n",
       "      <td>8174</td>\n",
       "      <td>130.854120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-03 09:01:00+00:00</th>\n",
       "      <td>131.10</td>\n",
       "      <td>131.17</td>\n",
       "      <td>130.87</td>\n",
       "      <td>157</td>\n",
       "      <td>130.87</td>\n",
       "      <td>8820</td>\n",
       "      <td>130.955243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-03 09:02:00+00:00</th>\n",
       "      <td>131.17</td>\n",
       "      <td>131.24</td>\n",
       "      <td>131.17</td>\n",
       "      <td>53</td>\n",
       "      <td>131.18</td>\n",
       "      <td>2112</td>\n",
       "      <td>131.208769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-03 09:03:00+00:00</th>\n",
       "      <td>131.28</td>\n",
       "      <td>131.29</td>\n",
       "      <td>131.19</td>\n",
       "      <td>90</td>\n",
       "      <td>131.19</td>\n",
       "      <td>3888</td>\n",
       "      <td>131.220790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-03 09:04:00+00:00</th>\n",
       "      <td>131.46</td>\n",
       "      <td>131.46</td>\n",
       "      <td>131.28</td>\n",
       "      <td>88</td>\n",
       "      <td>131.28</td>\n",
       "      <td>5984</td>\n",
       "      <td>131.327899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-17 00:55:00+00:00</th>\n",
       "      <td>183.00</td>\n",
       "      <td>183.03</td>\n",
       "      <td>183.00</td>\n",
       "      <td>45</td>\n",
       "      <td>183.03</td>\n",
       "      <td>1224</td>\n",
       "      <td>183.014261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-17 00:56:00+00:00</th>\n",
       "      <td>183.00</td>\n",
       "      <td>183.01</td>\n",
       "      <td>183.00</td>\n",
       "      <td>69</td>\n",
       "      <td>183.01</td>\n",
       "      <td>4641</td>\n",
       "      <td>183.001462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-17 00:57:00+00:00</th>\n",
       "      <td>183.01</td>\n",
       "      <td>183.04</td>\n",
       "      <td>183.01</td>\n",
       "      <td>21</td>\n",
       "      <td>183.04</td>\n",
       "      <td>958</td>\n",
       "      <td>183.030350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-17 00:58:00+00:00</th>\n",
       "      <td>183.05</td>\n",
       "      <td>183.05</td>\n",
       "      <td>183.04</td>\n",
       "      <td>21</td>\n",
       "      <td>183.04</td>\n",
       "      <td>671</td>\n",
       "      <td>183.043748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-17 00:59:00+00:00</th>\n",
       "      <td>183.04</td>\n",
       "      <td>183.04</td>\n",
       "      <td>183.04</td>\n",
       "      <td>36</td>\n",
       "      <td>183.04</td>\n",
       "      <td>1574</td>\n",
       "      <td>183.043148</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>194711 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            close    high     low  trade_count    open  \\\n",
       "timestamp                                                                \n",
       "2023-01-03 09:00:00+00:00  131.00  131.00  130.28          208  130.28   \n",
       "2023-01-03 09:01:00+00:00  131.10  131.17  130.87          157  130.87   \n",
       "2023-01-03 09:02:00+00:00  131.17  131.24  131.17           53  131.18   \n",
       "2023-01-03 09:03:00+00:00  131.28  131.29  131.19           90  131.19   \n",
       "2023-01-03 09:04:00+00:00  131.46  131.46  131.28           88  131.28   \n",
       "...                           ...     ...     ...          ...     ...   \n",
       "2024-01-17 00:55:00+00:00  183.00  183.03  183.00           45  183.03   \n",
       "2024-01-17 00:56:00+00:00  183.00  183.01  183.00           69  183.01   \n",
       "2024-01-17 00:57:00+00:00  183.01  183.04  183.01           21  183.04   \n",
       "2024-01-17 00:58:00+00:00  183.05  183.05  183.04           21  183.04   \n",
       "2024-01-17 00:59:00+00:00  183.04  183.04  183.04           36  183.04   \n",
       "\n",
       "                           volume        vwap  \n",
       "timestamp                                      \n",
       "2023-01-03 09:00:00+00:00    8174  130.854120  \n",
       "2023-01-03 09:01:00+00:00    8820  130.955243  \n",
       "2023-01-03 09:02:00+00:00    2112  131.208769  \n",
       "2023-01-03 09:03:00+00:00    3888  131.220790  \n",
       "2023-01-03 09:04:00+00:00    5984  131.327899  \n",
       "...                           ...         ...  \n",
       "2024-01-17 00:55:00+00:00    1224  183.014261  \n",
       "2024-01-17 00:56:00+00:00    4641  183.001462  \n",
       "2024-01-17 00:57:00+00:00     958  183.030350  \n",
       "2024-01-17 00:58:00+00:00     671  183.043748  \n",
       "2024-01-17 00:59:00+00:00    1574  183.043148  \n",
       "\n",
       "[194711 rows x 7 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AAPL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the indexes\n",
    "\n",
    "AAPL.sort_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Concatenate the ticker DataFrames\n",
    "# AAPL = pd.concat([AAPL, MSFT],axis=1, keys=['AAPL','MSFT'])\n",
    "\n",
    "# # Preview DataFrame\n",
    "# AAPL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice. Now we have the OHLC data here in our workspace, and we can move onto the next step of the process; data cleaning.\n",
    "\n",
    "### Data Cleaning\n",
    "\n",
    "Drop NA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>close</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>trade_count</th>\n",
       "      <th>open</th>\n",
       "      <th>volume</th>\n",
       "      <th>vwap</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-01-03 09:00:00+00:00</th>\n",
       "      <td>131.00</td>\n",
       "      <td>131.00</td>\n",
       "      <td>130.28</td>\n",
       "      <td>208</td>\n",
       "      <td>130.28</td>\n",
       "      <td>8174</td>\n",
       "      <td>130.854120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-03 09:01:00+00:00</th>\n",
       "      <td>131.10</td>\n",
       "      <td>131.17</td>\n",
       "      <td>130.87</td>\n",
       "      <td>157</td>\n",
       "      <td>130.87</td>\n",
       "      <td>8820</td>\n",
       "      <td>130.955243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-03 09:02:00+00:00</th>\n",
       "      <td>131.17</td>\n",
       "      <td>131.24</td>\n",
       "      <td>131.17</td>\n",
       "      <td>53</td>\n",
       "      <td>131.18</td>\n",
       "      <td>2112</td>\n",
       "      <td>131.208769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-03 09:03:00+00:00</th>\n",
       "      <td>131.28</td>\n",
       "      <td>131.29</td>\n",
       "      <td>131.19</td>\n",
       "      <td>90</td>\n",
       "      <td>131.19</td>\n",
       "      <td>3888</td>\n",
       "      <td>131.220790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-03 09:04:00+00:00</th>\n",
       "      <td>131.46</td>\n",
       "      <td>131.46</td>\n",
       "      <td>131.28</td>\n",
       "      <td>88</td>\n",
       "      <td>131.28</td>\n",
       "      <td>5984</td>\n",
       "      <td>131.327899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-17 00:55:00+00:00</th>\n",
       "      <td>183.00</td>\n",
       "      <td>183.03</td>\n",
       "      <td>183.00</td>\n",
       "      <td>45</td>\n",
       "      <td>183.03</td>\n",
       "      <td>1224</td>\n",
       "      <td>183.014261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-17 00:56:00+00:00</th>\n",
       "      <td>183.00</td>\n",
       "      <td>183.01</td>\n",
       "      <td>183.00</td>\n",
       "      <td>69</td>\n",
       "      <td>183.01</td>\n",
       "      <td>4641</td>\n",
       "      <td>183.001462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-17 00:57:00+00:00</th>\n",
       "      <td>183.01</td>\n",
       "      <td>183.04</td>\n",
       "      <td>183.01</td>\n",
       "      <td>21</td>\n",
       "      <td>183.04</td>\n",
       "      <td>958</td>\n",
       "      <td>183.030350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-17 00:58:00+00:00</th>\n",
       "      <td>183.05</td>\n",
       "      <td>183.05</td>\n",
       "      <td>183.04</td>\n",
       "      <td>21</td>\n",
       "      <td>183.04</td>\n",
       "      <td>671</td>\n",
       "      <td>183.043748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-17 00:59:00+00:00</th>\n",
       "      <td>183.04</td>\n",
       "      <td>183.04</td>\n",
       "      <td>183.04</td>\n",
       "      <td>36</td>\n",
       "      <td>183.04</td>\n",
       "      <td>1574</td>\n",
       "      <td>183.043148</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>194711 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            close    high     low  trade_count    open  \\\n",
       "timestamp                                                                \n",
       "2023-01-03 09:00:00+00:00  131.00  131.00  130.28          208  130.28   \n",
       "2023-01-03 09:01:00+00:00  131.10  131.17  130.87          157  130.87   \n",
       "2023-01-03 09:02:00+00:00  131.17  131.24  131.17           53  131.18   \n",
       "2023-01-03 09:03:00+00:00  131.28  131.29  131.19           90  131.19   \n",
       "2023-01-03 09:04:00+00:00  131.46  131.46  131.28           88  131.28   \n",
       "...                           ...     ...     ...          ...     ...   \n",
       "2024-01-17 00:55:00+00:00  183.00  183.03  183.00           45  183.03   \n",
       "2024-01-17 00:56:00+00:00  183.00  183.01  183.00           69  183.01   \n",
       "2024-01-17 00:57:00+00:00  183.01  183.04  183.01           21  183.04   \n",
       "2024-01-17 00:58:00+00:00  183.05  183.05  183.04           21  183.04   \n",
       "2024-01-17 00:59:00+00:00  183.04  183.04  183.04           36  183.04   \n",
       "\n",
       "                           volume        vwap  \n",
       "timestamp                                      \n",
       "2023-01-03 09:00:00+00:00    8174  130.854120  \n",
       "2023-01-03 09:01:00+00:00    8820  130.955243  \n",
       "2023-01-03 09:02:00+00:00    2112  131.208769  \n",
       "2023-01-03 09:03:00+00:00    3888  131.220790  \n",
       "2023-01-03 09:04:00+00:00    5984  131.327899  \n",
       "...                           ...         ...  \n",
       "2024-01-17 00:55:00+00:00    1224  183.014261  \n",
       "2024-01-17 00:56:00+00:00    4641  183.001462  \n",
       "2024-01-17 00:57:00+00:00     958  183.030350  \n",
       "2024-01-17 00:58:00+00:00     671  183.043748  \n",
       "2024-01-17 00:59:00+00:00    1574  183.043148  \n",
       "\n",
       "[194711 rows x 7 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop NA\n",
    "AAPL = AAPL.dropna()\n",
    "\n",
    "AAPL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For 1 minute: Dropping the NaN just took out about 600 rows of data. Did it take out the whole column given the date? That is not good, since if we have the data for one stock at a given minute but not the other, we don't want to throw out that info for the one stock. \n",
    "\n",
    "3166 to 2405 rows after dropping NaN.\n",
    "\n",
    "We will come back to this. Remember, we don't want little things like this from holding us back from implementing this. Just make a note of these little issues and crush them during the next iteration. \n",
    "\n",
    "UPDATE 1: With 3 minutes, we start with 1200 rows, then have 1014 after dropping NaN. \n",
    "\n",
    "Seems to get better when we zoom out... We will most probably just source better data, however. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now save this cleaned dataframe to a new .csv\n",
    "AAPL.to_csv('../algotrader2/Resources/aapl_OHLCV_1min_df.csv', index=\"True\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our next step is to generate the features from the data set that we will train our model with. \n",
    "\n",
    "[Feature Creation->](/Users/montygash/Desktop/ETAlgo/tradingbot/nn_feature_creation.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have the indicators and what we are trying to predict (actual returns). \n",
    "\n",
    "We will set the indicators to our 'X' and the actual return as our 'y'.\n",
    "\n",
    "In this case, we have two different stocks that we are trying to predict.\n",
    "- AAPL data will be used to predict AAPL actual returns.\n",
    "- MSFT data will be used to predict MSFT actual returns. \n",
    "- Is this how we want the algorithm to be? To only train itself on a particular stock? \n",
    "    - No... I want it to be trained on MULTIPLE stocks. So it is trained on both MSFT, AAPL, and even TSLA, AMD, NVDA... and then I deploy it on any stock that I want to deploy it onto. \n",
    "    - This is a major issue that I need to resolve. \n",
    "\n",
    "\n",
    "Let's just begin by implementing the neural network algorithm on only AAPL."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This begs another question: Do we only need to shift it back one? Since we are using 1 minute candles? Maybe we should be shifting it back more than one one minute bar?... We will revisit this later.\n",
    "\n",
    "\n",
    "We are trying to predict y, which is whether or not we should buy or sell the stock at that given time.\n",
    "\n",
    "I was confused and tried to implement by making actual returns be the y, but we actually want to generate signals, where the bot chooses whether to short or long the stock based on the predicted returns during the next 1 minute candle (we will probably revisit the 1-minute candle idea. I'm not sure that we want the bot to send out that many signals. Maybe we train it with different OHLC time-frames)\n",
    "\n",
    "So the first step in making the bot generate signals is to define when the signal is 1 (buy), and -1(sell).\n",
    "\n",
    "We want the bot to sell when the expected returns is negative, and buy when positive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "deploy. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice! Now I want to take only the necessary portion of this page onto a new .ipynb. We will make it nice and clean. We will only include the data prep portion and the neural networks model. We will keep our comments more breif to improve the readability of the overall idea--the 'gist' of all of the moving parts--from somewhat of a bird's eye view. We will divide the code up strategically, so that we can dive into each moving part and tune it as needed. Our model should become more and more sofisticated and accurate over future iterations until our goal of consistient profitability is met."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
