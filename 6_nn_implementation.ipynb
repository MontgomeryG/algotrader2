{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import hvplot.pandas\n",
    "from pathlib import Path\n",
    "from finta import TA\n",
    "from pandas.tseries.offsets import DateOffset\n",
    "import os\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "import alpaca_trade_api as tradeapi\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import indicator dataframe\n",
    "# Start with 1-minute... alghough we would like to attatch them all together soon.\n",
    "df = pd.read_csv(\"../algotrader2/resources/aapl_1min_pivot_point_indicator_df.csv\")\n",
    "df.head()\n",
    "\n",
    "# df = pd.read_csv(\"../algotrader/resources/aapl_3min_pivot_point_indicator_df.csv\")\n",
    "# df.head()\n",
    "\n",
    "# df = pd.read_csv(\"../algotrader/resources/aapl_1min_pivot_point_indicator_df.csv\")\n",
    "# df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# our df does not have date-time\n",
    "hello = df['timestamp']\n",
    "hello"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create our timestamp column as a datetime index, then save it as our index\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "\n",
    "hello = df['timestamp']\n",
    "hello"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.set_index('timestamp', inplace=True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X is everything except the signal column\n",
    "X = df.drop('signal', axis=1)\n",
    "\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We should use the .shift() function so that our algorithm predicts the minute before realtime\n",
    "# Drop the row with NaN values \n",
    "X = X.shift().dropna()\n",
    "\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We may look to consider what it would do if we changed the amount that we shifted by. Perhaps we tried predicting 5 minutes into the future... how about an hour?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y is the signal column\n",
    "y = df[(\"signal\")]\n",
    "\n",
    "y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set start of training period\n",
    "training_begin = X.index.min()\n",
    "\n",
    "print(training_begin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select ending period for the training data. Since we pulled a year's worth of data\n",
    "# we will train on 9 months and then test with the rest\n",
    "training_end = X.index.min() + DateOffset(months=9)\n",
    "\n",
    "print(training_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the X_train and y_train DataFrames\n",
    "X_train = X.loc[training_begin:training_end]\n",
    "y_train = y.loc[training_begin:training_end]\n",
    "\n",
    "# Generate the X_test and y_test DataFrames\n",
    "X_test = X.loc[training_end:]\n",
    "y_test = y.loc[training_end:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a StandardScaler instance\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Apply the scaler model to fit the X-train data\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Transform the X_train and X_test DataFrames using the X_scaler\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(X_train_scaled.shape)\n",
    "display(X_test_scaled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "# Use RandomOverSampler to resample the datase using random_state=1\n",
    "ros = RandomOverSampler(random_state=1)\n",
    "X_resampled, y_resampled = ros.fit_resample(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(X_train_scaled.shape)\n",
    "display(X_test_scaled.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now that we have scaled our data, we can build our neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_predictors = len(X.columns)\n",
    "\n",
    "# We have 3 possible outcomes, and we are trying to predict the stock/indicators to be in position -1, 0, or 1\n",
    "num_classes = 1\n",
    "\n",
    "num_predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add dense layer(s)\n",
    "nn_model.add(Dense(10, input_dim=num_predictors, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop-out layer(s)\n",
    "# nn_model.add(Dropout(.2,input_shape=(10,)))\n",
    "\n",
    "# Add dense layer, add Regularization\n",
    "#model.add(Dense(5, activation='relu', kernel_regularized=l2(0.01), bias_regularized=l2(0.01)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add output layer\n",
    "# Number of outputs equals number of classes\n",
    "#nn_model.add(Dense(num_classes))\n",
    "nn_model.add(Dense(num_classes, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "nn_model.compile(loss=\"categorical_crossentropy\",\n",
    "              optimizer=\"adam\",\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Summarize model\n",
    "nn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit model\n",
    "num_epochs = 100\n",
    "\n",
    "nn_model.fit(X_train_scaled, y_train,\n",
    "          epochs=num_epochs,\n",
    "          batch_size=100,\n",
    "          validation_split=0.2,     # This 'validation_split' is telling the neural network to keep 20% of the data to validate its score on the training set... this is to help AVOID OVERFITTING. \n",
    "          shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show model loss and accuracy\n",
    "\n",
    "# Evaluate the model loss and accuracy metrics using the evaluate method and the test data\n",
    "model_loss, model_accuracy = nn_model.evaluate(X_test_scaled, y_test, verbose=2)\n",
    "\n",
    "# Display the evaluation results\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we backtest with the TEST portion of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict values using testing data\n",
    "nn_test_predictions = nn_model.predict(X_test_scaled)\n",
    "nn_train_predictions = nn_model.predict(X_train_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Evaluate the model using a classification report\n",
    "# from sklearn.metrics import classification_report\n",
    "# training_report = classification_report(nn_train_predictions, nn_test_predictions)\n",
    "# print(training_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Evaluate the model's ability to predict the trading signal for the testing data using a classification report\n",
    "# training_report = classification_report(y_test, testing_signal_predictions)\n",
    "# print(training_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save model history for further manipulation\n",
    "# model_history = model.history.model_history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Now we can plot the accuracy for training and validation\n",
    "\n",
    "# training_results = pd.DataFrame(index=range(1, num_epochs+1))\n",
    "# training_results['Training'] = model_history['categorical_accuracy']\n",
    "# training_results['Validation'] = model_history['val_categorical_accuracy']\n",
    "# training_results.plot(title = 'Training and Validation Performance')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now using the 3 minute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import indicator dataframe\n",
    "df = pd.read_csv(\"../algotrader2/resources/aapl_3min_pivot_point_indicator_df.csv\")\n",
    "df.head()\n",
    "\n",
    "# df = pd.read_csv(\"../algotrader2/resources/aapl_1min_pivot_point_indicator_df.csv\")\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create our timestamp column as a datetime index, then save it as our index\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "df.set_index('timestamp', inplace=True)\n",
    "# X is everything except the signal column\n",
    "X = df.drop('signal', axis=1)\n",
    "# We should use the .shift() function so that our algorithm predicts the minute before realtime\n",
    "# Drop the row with NaN values \n",
    "X = X.shift().dropna()\n",
    "display(X.head())\n",
    "y = df[(\"signal\")]\n",
    "# Set start of training period\n",
    "training_begin = X.index.min()\n",
    "print(f\"Start date: {training_begin}\")\n",
    "# Select ending period for the training data. Since we pulled a year's worth of data\n",
    "# we will train on 9 months and then test with the rest\n",
    "training_end = X.index.min() + DateOffset(months=9)\n",
    "print(f\"End date: {training_end}\")\n",
    "# Generate the X_train and y_train DataFrames\n",
    "X_train = X.loc[training_begin:training_end]\n",
    "y_train = y.loc[training_begin:training_end]\n",
    "\n",
    "# Generate the X_test and y_test DataFrames\n",
    "X_test = X.loc[training_end:]\n",
    "y_test = y.loc[training_end:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a StandardScaler instance\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Apply the scaler model to fit the X-train data\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Transform the X_train and X_test DataFrames using the X_scaler\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)\n",
    "\n",
    "display(X_train_scaled.shape)\n",
    "display(X_test_scaled.shape)\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "# Use RandomOverSampler to resample the datase using random_state=1\n",
    "ros = RandomOverSampler(random_state=1)\n",
    "X_resampled, y_resampled = ros.fit_resample(X_train_scaled, y_train)\n",
    "display(X_train_scaled.shape)\n",
    "display(X_test_scaled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NEURAL NETWORK\n",
    "num_predictors = len(X.columns)\n",
    "num_classes = 1\n",
    "nn_model = Sequential()\n",
    "# Add dense layer(s)\n",
    "nn_model.add(Dense(10, input_dim=num_predictors, activation='relu'))\n",
    "# Drop-out layer(s)\n",
    "# nn_model.add(Dropout(.2,input_shape=(10,)))\n",
    "# Add dense layer, add Regularization\n",
    "#model.add(Dense(5, activation='relu', kernel_regularized=l2(0.01), bias_regularized=l2(0.01)))\n",
    "# Add output layer\n",
    "# Number of outputs equals number of classes\n",
    "#nn_model.add(Dense(num_classes))\n",
    "nn_model.add(Dense(num_classes, activation=\"softmax\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "nn_model.compile(loss=\"categorical_crossentropy\",\n",
    "              optimizer=\"adam\",\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Summarize model\n",
    "nn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit model\n",
    "num_epochs = 100\n",
    "\n",
    "nn_model.fit(X_train_scaled, y_train,\n",
    "          epochs=num_epochs,\n",
    "          batch_size=100,\n",
    "          validation_split=0.2,     # This 'validation_split' is telling the neural network to keep 20% of the data to validate its score on the training set... this is to help AVOID OVERFITTING. \n",
    "          shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show model loss and accuracy\n",
    "\n",
    "# Evaluate the model loss and accuracy metrics using the evaluate method and the test data\n",
    "model_loss, model_accuracy = nn_model.evaluate(X_test_scaled, y_test, verbose=2)\n",
    "\n",
    "# Display the evaluation results\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict values using testing data\n",
    "nn_test_predictions = nn_model.predict(X_test_scaled)\n",
    "nn_train_predictions = nn_model.predict(X_train_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Evaluate the model using a classification report\n",
    "# from sklearn.metrics import classification_report\n",
    "# training_report = classification_report(nn_train_predictions, nn_test_predictions)\n",
    "# print(training_report)\n",
    "\n",
    "# # Evaluate the model's ability to predict the trading signal for the testing data using a classification report\n",
    "# training_report = classification_report(y_test, testing_signal_predictions)\n",
    "# print(training_report)\n",
    "\n",
    "# # Save model history for further manipulation\n",
    "# model_history = model.history.model_history.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now 15 minute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import indicator dataframe\n",
    "df = pd.read_csv(\"../algotrader2/resources/aapl_1min_pivot_point_indicator_df.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create our timestamp column as a datetime index, then save it as our index\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "df.set_index('timestamp', inplace=True)\n",
    "# X is everything except the signal column\n",
    "X = df.drop('signal', axis=1)\n",
    "# We should use the .shift() function so that our algorithm predicts the minute before realtime\n",
    "# Drop the row with NaN values \n",
    "X = X.shift().dropna()\n",
    "display(X.head())\n",
    "y = df[(\"signal\")]\n",
    "# Set start of training period\n",
    "training_begin = X.index.min()\n",
    "print(f\"Start date: {training_begin}\")\n",
    "# Select ending period for the training data. Since we pulled a year's worth of data\n",
    "# we will train on 9 months and then test with the rest\n",
    "training_end = X.index.min() + DateOffset(months=9)\n",
    "print(f\"End date: {training_end}\")\n",
    "# Generate the X_train and y_train DataFrames\n",
    "X_train = X.loc[training_begin:training_end]\n",
    "y_train = y.loc[training_begin:training_end]\n",
    "\n",
    "# Generate the X_test and y_test DataFrames\n",
    "X_test = X.loc[training_end:]\n",
    "y_test = y.loc[training_end:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a StandardScaler instance\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Apply the scaler model to fit the X-train data\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Transform the X_train and X_test DataFrames using the X_scaler\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)\n",
    "\n",
    "display(X_train_scaled.shape)\n",
    "display(X_test_scaled.shape)\n",
    "\n",
    "# from imblearn.over_sampling import RandomOverSampler\n",
    "# Use RandomOverSampler to resample the datase using random_state=1\n",
    "ros = RandomOverSampler(random_state=1)\n",
    "X_resampled, y_resampled = ros.fit_resample(X_train_scaled, y_train)\n",
    "display(X_train_scaled.shape)\n",
    "display(X_test_scaled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NEURAL NETWORK\n",
    "num_predictors = len(X.columns)\n",
    "num_classes = 1\n",
    "nn_model = Sequential()\n",
    "# Add dense layer(s)\n",
    "nn_model.add(Dense(10, input_dim=num_predictors, activation='relu'))\n",
    "# Drop-out layer(s)\n",
    "# nn_model.add(Dropout(.2,input_shape=(10,)))\n",
    "# Add dense layer, add Regularization\n",
    "#model.add(Dense(5, activation='relu', kernel_regularized=l2(0.01), bias_regularized=l2(0.01)))\n",
    "# Add output layer\n",
    "# Number of outputs equals number of classes\n",
    "#nn_model.add(Dense(num_classes))\n",
    "nn_model.add(Dense(num_classes, activation=\"softmax\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "nn_model.compile(loss=\"categorical_crossentropy\",\n",
    "              optimizer=\"adam\",\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Summarize model\n",
    "nn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit model\n",
    "num_epochs = 100\n",
    "\n",
    "nn_model.fit(X_train_scaled, y_train,\n",
    "          epochs=num_epochs,\n",
    "          batch_size=100,\n",
    "          validation_split=0.2,     # This 'validation_split' is telling the neural network to keep 20% of the data to validate its score on the training set... this is to help AVOID OVERFITTING. \n",
    "          shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show model loss and accuracy\n",
    "\n",
    "# Evaluate the model loss and accuracy metrics using the evaluate method and the test data\n",
    "model_loss, model_accuracy = nn_model.evaluate(X_test_scaled, y_test, verbose=2)\n",
    "\n",
    "# Display the evaluation results\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict values using testing data\n",
    "nn_test_predictions = nn_model.predict(X_test_scaled)\n",
    "nn_train_predictions = nn_model.predict(X_train_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_test_predictions[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Evaluate the model using a classification report\n",
    "# from sklearn.metrics import classification_report\n",
    "# training_report = classification_report(nn_train_predictions, nn_test_predictions)\n",
    "# print(training_report)\n",
    "\n",
    "# # Evaluate the model's ability to predict the trading signal for the testing data using a classification report\n",
    "# training_report = classification_report(y_test, testing_signal_predictions)\n",
    "# print(training_report)\n",
    "\n",
    "# # Save model history for further manipulation\n",
    "# model_history = model.history.model_history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Deployment (Hypothetical)\n",
    "# while True:\n",
    "#     current_data = your_trading_api.get_real_time_data()\n",
    "#     current_data_processed = preprocess_data(current_data)\n",
    "#     prediction = model.predict(current_data_processed)\n",
    "#     if prediction > some_threshold:\n",
    "#         your_trading_api.execute_trade()\n",
    "\n",
    "# # Placeholder Functions\n",
    "# def combine_data(historical, news):\n",
    "#     # Combine and return data\n",
    "#     pass\n",
    "\n",
    "# def split_data(data):\n",
    "#     # Split and return data\n",
    "#     pass\n",
    "\n",
    "# def backtest_strategy(model, data):\n",
    "#     # Implement backtesting logic\n",
    "#     pass\n",
    "\n",
    "# def preprocess_data(data):\n",
    "#     # Data preprocessing steps\n",
    "#     pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
