{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import hvplot.pandas\n",
    "from pathlib import Path\n",
    "from finta import TA\n",
    "from pandas.tseries.offsets import DateOffset\n",
    "import os\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "import alpaca_trade_api as tradeapi\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>close</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>trade_count</th>\n",
       "      <th>open</th>\n",
       "      <th>volume</th>\n",
       "      <th>vwap</th>\n",
       "      <th>pct_returns</th>\n",
       "      <th>SMA5</th>\n",
       "      <th>...</th>\n",
       "      <th>COPP</th>\n",
       "      <th>CMO</th>\n",
       "      <th>FISH</th>\n",
       "      <th>SQZMI</th>\n",
       "      <th>VPT</th>\n",
       "      <th>FVE</th>\n",
       "      <th>VFI</th>\n",
       "      <th>MSD</th>\n",
       "      <th>STC</th>\n",
       "      <th>signal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-01-03 15:04:00+00:00</td>\n",
       "      <td>126.5001</td>\n",
       "      <td>126.880</td>\n",
       "      <td>126.4166</td>\n",
       "      <td>5733</td>\n",
       "      <td>126.820</td>\n",
       "      <td>513722</td>\n",
       "      <td>126.624892</td>\n",
       "      <td>-0.002516</td>\n",
       "      <td>126.87386</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.878051</td>\n",
       "      <td>-65.583650</td>\n",
       "      <td>-4.458619</td>\n",
       "      <td>False</td>\n",
       "      <td>-9.952525e+06</td>\n",
       "      <td>-43.838967</td>\n",
       "      <td>-25.409400</td>\n",
       "      <td>1.034633</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-01-03 15:05:00+00:00</td>\n",
       "      <td>126.8500</td>\n",
       "      <td>126.895</td>\n",
       "      <td>126.4400</td>\n",
       "      <td>3763</td>\n",
       "      <td>126.505</td>\n",
       "      <td>362900</td>\n",
       "      <td>126.625878</td>\n",
       "      <td>0.002766</td>\n",
       "      <td>126.80786</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.719298</td>\n",
       "      <td>-40.134546</td>\n",
       "      <td>-4.465828</td>\n",
       "      <td>False</td>\n",
       "      <td>-9.402193e+06</td>\n",
       "      <td>-43.321203</td>\n",
       "      <td>-24.707011</td>\n",
       "      <td>0.967187</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-01-03 15:06:00+00:00</td>\n",
       "      <td>126.5800</td>\n",
       "      <td>126.870</td>\n",
       "      <td>126.5300</td>\n",
       "      <td>2930</td>\n",
       "      <td>126.860</td>\n",
       "      <td>240388</td>\n",
       "      <td>126.664497</td>\n",
       "      <td>-0.002128</td>\n",
       "      <td>126.71786</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.551580</td>\n",
       "      <td>-47.104800</td>\n",
       "      <td>-4.057573</td>\n",
       "      <td>False</td>\n",
       "      <td>-9.798127e+06</td>\n",
       "      <td>-39.135081</td>\n",
       "      <td>-24.923630</td>\n",
       "      <td>0.907692</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-01-03 15:07:00+00:00</td>\n",
       "      <td>126.7100</td>\n",
       "      <td>126.870</td>\n",
       "      <td>126.5000</td>\n",
       "      <td>3189</td>\n",
       "      <td>126.580</td>\n",
       "      <td>289721</td>\n",
       "      <td>126.666956</td>\n",
       "      <td>0.001027</td>\n",
       "      <td>126.69186</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.402012</td>\n",
       "      <td>-38.479113</td>\n",
       "      <td>-3.693347</td>\n",
       "      <td>False</td>\n",
       "      <td>-9.594539e+06</td>\n",
       "      <td>-32.305140</td>\n",
       "      <td>-24.862300</td>\n",
       "      <td>0.792548</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-01-03 15:08:00+00:00</td>\n",
       "      <td>126.7066</td>\n",
       "      <td>126.760</td>\n",
       "      <td>126.5601</td>\n",
       "      <td>2861</td>\n",
       "      <td>126.705</td>\n",
       "      <td>255144</td>\n",
       "      <td>126.687038</td>\n",
       "      <td>-0.000027</td>\n",
       "      <td>126.66934</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.241145</td>\n",
       "      <td>-38.583764</td>\n",
       "      <td>-3.567436</td>\n",
       "      <td>False</td>\n",
       "      <td>-9.590454e+06</td>\n",
       "      <td>-32.682043</td>\n",
       "      <td>-24.646221</td>\n",
       "      <td>0.705603</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 99 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   timestamp     close     high       low  trade_count  \\\n",
       "0  2023-01-03 15:04:00+00:00  126.5001  126.880  126.4166         5733   \n",
       "1  2023-01-03 15:05:00+00:00  126.8500  126.895  126.4400         3763   \n",
       "2  2023-01-03 15:06:00+00:00  126.5800  126.870  126.5300         2930   \n",
       "3  2023-01-03 15:07:00+00:00  126.7100  126.870  126.5000         3189   \n",
       "4  2023-01-03 15:08:00+00:00  126.7066  126.760  126.5601         2861   \n",
       "\n",
       "      open  volume        vwap  pct_returns       SMA5  ...      COPP  \\\n",
       "0  126.820  513722  126.624892    -0.002516  126.87386  ... -2.878051   \n",
       "1  126.505  362900  126.625878     0.002766  126.80786  ... -2.719298   \n",
       "2  126.860  240388  126.664497    -0.002128  126.71786  ... -2.551580   \n",
       "3  126.580  289721  126.666956     0.001027  126.69186  ... -2.402012   \n",
       "4  126.705  255144  126.687038    -0.000027  126.66934  ... -2.241145   \n",
       "\n",
       "         CMO      FISH  SQZMI           VPT        FVE        VFI       MSD  \\\n",
       "0 -65.583650 -4.458619  False -9.952525e+06 -43.838967 -25.409400  1.034633   \n",
       "1 -40.134546 -4.465828  False -9.402193e+06 -43.321203 -24.707011  0.967187   \n",
       "2 -47.104800 -4.057573  False -9.798127e+06 -39.135081 -24.923630  0.907692   \n",
       "3 -38.479113 -3.693347  False -9.594539e+06 -32.305140 -24.862300  0.792548   \n",
       "4 -38.583764 -3.567436  False -9.590454e+06 -32.682043 -24.646221  0.705603   \n",
       "\n",
       "   STC  signal  \n",
       "0  0.0       0  \n",
       "1  0.0       0  \n",
       "2  0.0       0  \n",
       "3  0.0       0  \n",
       "4  0.0       0  \n",
       "\n",
       "[5 rows x 99 columns]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import indicator dataframe\n",
    "# Start with 1-minute... alghough we would like to attatch them all together soon.\n",
    "df = pd.read_csv(\"../algotrader2/resources/aapl_1min_pivot_point_indicator_df.csv\")\n",
    "df.head()\n",
    "\n",
    "# df = pd.read_csv(\"../algotrader/resources/aapl_3min_pivot_point_indicator_df.csv\")\n",
    "# df.head()\n",
    "\n",
    "# df = pd.read_csv(\"../algotrader/resources/aapl_1min_pivot_point_indicator_df.csv\")\n",
    "# df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         2023-01-03 15:04:00+00:00\n",
       "1         2023-01-03 15:05:00+00:00\n",
       "2         2023-01-03 15:06:00+00:00\n",
       "3         2023-01-03 15:07:00+00:00\n",
       "4         2023-01-03 15:08:00+00:00\n",
       "                    ...            \n",
       "153677    2024-01-17 00:47:00+00:00\n",
       "153678    2024-01-17 00:52:00+00:00\n",
       "153679    2024-01-17 00:55:00+00:00\n",
       "153680    2024-01-17 00:57:00+00:00\n",
       "153681    2024-01-17 00:58:00+00:00\n",
       "Name: timestamp, Length: 153682, dtype: object"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# our df does not have date-time\n",
    "hello = df['timestamp']\n",
    "hello"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        2023-01-03 15:04:00+00:00\n",
       "1        2023-01-03 15:05:00+00:00\n",
       "2        2023-01-03 15:06:00+00:00\n",
       "3        2023-01-03 15:07:00+00:00\n",
       "4        2023-01-03 15:08:00+00:00\n",
       "                    ...           \n",
       "153677   2024-01-17 00:47:00+00:00\n",
       "153678   2024-01-17 00:52:00+00:00\n",
       "153679   2024-01-17 00:55:00+00:00\n",
       "153680   2024-01-17 00:57:00+00:00\n",
       "153681   2024-01-17 00:58:00+00:00\n",
       "Name: timestamp, Length: 153682, dtype: datetime64[ns, UTC]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create our timestamp column as a datetime index, then save it as our index\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "\n",
    "hello = df['timestamp']\n",
    "hello"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>close</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>trade_count</th>\n",
       "      <th>open</th>\n",
       "      <th>volume</th>\n",
       "      <th>vwap</th>\n",
       "      <th>pct_returns</th>\n",
       "      <th>SMA5</th>\n",
       "      <th>SMA10</th>\n",
       "      <th>...</th>\n",
       "      <th>COPP</th>\n",
       "      <th>CMO</th>\n",
       "      <th>FISH</th>\n",
       "      <th>SQZMI</th>\n",
       "      <th>VPT</th>\n",
       "      <th>FVE</th>\n",
       "      <th>VFI</th>\n",
       "      <th>MSD</th>\n",
       "      <th>STC</th>\n",
       "      <th>signal</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-01-03 15:04:00+00:00</th>\n",
       "      <td>126.5001</td>\n",
       "      <td>126.880</td>\n",
       "      <td>126.4166</td>\n",
       "      <td>5733</td>\n",
       "      <td>126.820</td>\n",
       "      <td>513722</td>\n",
       "      <td>126.624892</td>\n",
       "      <td>-0.002516</td>\n",
       "      <td>126.87386</td>\n",
       "      <td>127.15340</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.878051</td>\n",
       "      <td>-65.583650</td>\n",
       "      <td>-4.458619</td>\n",
       "      <td>False</td>\n",
       "      <td>-9.952525e+06</td>\n",
       "      <td>-43.838967</td>\n",
       "      <td>-25.409400</td>\n",
       "      <td>1.034633</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-03 15:05:00+00:00</th>\n",
       "      <td>126.8500</td>\n",
       "      <td>126.895</td>\n",
       "      <td>126.4400</td>\n",
       "      <td>3763</td>\n",
       "      <td>126.505</td>\n",
       "      <td>362900</td>\n",
       "      <td>126.625878</td>\n",
       "      <td>0.002766</td>\n",
       "      <td>126.80786</td>\n",
       "      <td>127.06139</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.719298</td>\n",
       "      <td>-40.134546</td>\n",
       "      <td>-4.465828</td>\n",
       "      <td>False</td>\n",
       "      <td>-9.402193e+06</td>\n",
       "      <td>-43.321203</td>\n",
       "      <td>-24.707011</td>\n",
       "      <td>0.967187</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-03 15:06:00+00:00</th>\n",
       "      <td>126.5800</td>\n",
       "      <td>126.870</td>\n",
       "      <td>126.5300</td>\n",
       "      <td>2930</td>\n",
       "      <td>126.860</td>\n",
       "      <td>240388</td>\n",
       "      <td>126.664497</td>\n",
       "      <td>-0.002128</td>\n",
       "      <td>126.71786</td>\n",
       "      <td>126.94739</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.551580</td>\n",
       "      <td>-47.104800</td>\n",
       "      <td>-4.057573</td>\n",
       "      <td>False</td>\n",
       "      <td>-9.798127e+06</td>\n",
       "      <td>-39.135081</td>\n",
       "      <td>-24.923630</td>\n",
       "      <td>0.907692</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-03 15:07:00+00:00</th>\n",
       "      <td>126.7100</td>\n",
       "      <td>126.870</td>\n",
       "      <td>126.5000</td>\n",
       "      <td>3189</td>\n",
       "      <td>126.580</td>\n",
       "      <td>289721</td>\n",
       "      <td>126.666956</td>\n",
       "      <td>0.001027</td>\n",
       "      <td>126.69186</td>\n",
       "      <td>126.87129</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.402012</td>\n",
       "      <td>-38.479113</td>\n",
       "      <td>-3.693347</td>\n",
       "      <td>False</td>\n",
       "      <td>-9.594539e+06</td>\n",
       "      <td>-32.305140</td>\n",
       "      <td>-24.862300</td>\n",
       "      <td>0.792548</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-03 15:08:00+00:00</th>\n",
       "      <td>126.7066</td>\n",
       "      <td>126.760</td>\n",
       "      <td>126.5601</td>\n",
       "      <td>2861</td>\n",
       "      <td>126.705</td>\n",
       "      <td>255144</td>\n",
       "      <td>126.687038</td>\n",
       "      <td>-0.000027</td>\n",
       "      <td>126.66934</td>\n",
       "      <td>126.81495</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.241145</td>\n",
       "      <td>-38.583764</td>\n",
       "      <td>-3.567436</td>\n",
       "      <td>False</td>\n",
       "      <td>-9.590454e+06</td>\n",
       "      <td>-32.682043</td>\n",
       "      <td>-24.646221</td>\n",
       "      <td>0.705603</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 98 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              close     high       low  trade_count     open  \\\n",
       "timestamp                                                                      \n",
       "2023-01-03 15:04:00+00:00  126.5001  126.880  126.4166         5733  126.820   \n",
       "2023-01-03 15:05:00+00:00  126.8500  126.895  126.4400         3763  126.505   \n",
       "2023-01-03 15:06:00+00:00  126.5800  126.870  126.5300         2930  126.860   \n",
       "2023-01-03 15:07:00+00:00  126.7100  126.870  126.5000         3189  126.580   \n",
       "2023-01-03 15:08:00+00:00  126.7066  126.760  126.5601         2861  126.705   \n",
       "\n",
       "                           volume        vwap  pct_returns       SMA5  \\\n",
       "timestamp                                                               \n",
       "2023-01-03 15:04:00+00:00  513722  126.624892    -0.002516  126.87386   \n",
       "2023-01-03 15:05:00+00:00  362900  126.625878     0.002766  126.80786   \n",
       "2023-01-03 15:06:00+00:00  240388  126.664497    -0.002128  126.71786   \n",
       "2023-01-03 15:07:00+00:00  289721  126.666956     0.001027  126.69186   \n",
       "2023-01-03 15:08:00+00:00  255144  126.687038    -0.000027  126.66934   \n",
       "\n",
       "                               SMA10  ...      COPP        CMO      FISH  \\\n",
       "timestamp                             ...                                  \n",
       "2023-01-03 15:04:00+00:00  127.15340  ... -2.878051 -65.583650 -4.458619   \n",
       "2023-01-03 15:05:00+00:00  127.06139  ... -2.719298 -40.134546 -4.465828   \n",
       "2023-01-03 15:06:00+00:00  126.94739  ... -2.551580 -47.104800 -4.057573   \n",
       "2023-01-03 15:07:00+00:00  126.87129  ... -2.402012 -38.479113 -3.693347   \n",
       "2023-01-03 15:08:00+00:00  126.81495  ... -2.241145 -38.583764 -3.567436   \n",
       "\n",
       "                           SQZMI           VPT        FVE        VFI  \\\n",
       "timestamp                                                              \n",
       "2023-01-03 15:04:00+00:00  False -9.952525e+06 -43.838967 -25.409400   \n",
       "2023-01-03 15:05:00+00:00  False -9.402193e+06 -43.321203 -24.707011   \n",
       "2023-01-03 15:06:00+00:00  False -9.798127e+06 -39.135081 -24.923630   \n",
       "2023-01-03 15:07:00+00:00  False -9.594539e+06 -32.305140 -24.862300   \n",
       "2023-01-03 15:08:00+00:00  False -9.590454e+06 -32.682043 -24.646221   \n",
       "\n",
       "                                MSD  STC  signal  \n",
       "timestamp                                         \n",
       "2023-01-03 15:04:00+00:00  1.034633  0.0       0  \n",
       "2023-01-03 15:05:00+00:00  0.967187  0.0       0  \n",
       "2023-01-03 15:06:00+00:00  0.907692  0.0       0  \n",
       "2023-01-03 15:07:00+00:00  0.792548  0.0       0  \n",
       "2023-01-03 15:08:00+00:00  0.705603  0.0       0  \n",
       "\n",
       "[5 rows x 98 columns]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.set_index('timestamp', inplace=True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>close</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>trade_count</th>\n",
       "      <th>open</th>\n",
       "      <th>volume</th>\n",
       "      <th>vwap</th>\n",
       "      <th>pct_returns</th>\n",
       "      <th>SMA5</th>\n",
       "      <th>SMA10</th>\n",
       "      <th>...</th>\n",
       "      <th>CCI</th>\n",
       "      <th>COPP</th>\n",
       "      <th>CMO</th>\n",
       "      <th>FISH</th>\n",
       "      <th>SQZMI</th>\n",
       "      <th>VPT</th>\n",
       "      <th>FVE</th>\n",
       "      <th>VFI</th>\n",
       "      <th>MSD</th>\n",
       "      <th>STC</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-01-03 15:04:00+00:00</th>\n",
       "      <td>126.5001</td>\n",
       "      <td>126.880</td>\n",
       "      <td>126.4166</td>\n",
       "      <td>5733</td>\n",
       "      <td>126.820</td>\n",
       "      <td>513722</td>\n",
       "      <td>126.624892</td>\n",
       "      <td>-0.002516</td>\n",
       "      <td>126.87386</td>\n",
       "      <td>127.15340</td>\n",
       "      <td>...</td>\n",
       "      <td>-116.423590</td>\n",
       "      <td>-2.878051</td>\n",
       "      <td>-65.583650</td>\n",
       "      <td>-4.458619</td>\n",
       "      <td>False</td>\n",
       "      <td>-9.952525e+06</td>\n",
       "      <td>-43.838967</td>\n",
       "      <td>-25.409400</td>\n",
       "      <td>1.034633</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-03 15:05:00+00:00</th>\n",
       "      <td>126.8500</td>\n",
       "      <td>126.895</td>\n",
       "      <td>126.4400</td>\n",
       "      <td>3763</td>\n",
       "      <td>126.505</td>\n",
       "      <td>362900</td>\n",
       "      <td>126.625878</td>\n",
       "      <td>0.002766</td>\n",
       "      <td>126.80786</td>\n",
       "      <td>127.06139</td>\n",
       "      <td>...</td>\n",
       "      <td>-101.126762</td>\n",
       "      <td>-2.719298</td>\n",
       "      <td>-40.134546</td>\n",
       "      <td>-4.465828</td>\n",
       "      <td>False</td>\n",
       "      <td>-9.402193e+06</td>\n",
       "      <td>-43.321203</td>\n",
       "      <td>-24.707011</td>\n",
       "      <td>0.967187</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-03 15:06:00+00:00</th>\n",
       "      <td>126.5800</td>\n",
       "      <td>126.870</td>\n",
       "      <td>126.5300</td>\n",
       "      <td>2930</td>\n",
       "      <td>126.860</td>\n",
       "      <td>240388</td>\n",
       "      <td>126.664497</td>\n",
       "      <td>-0.002128</td>\n",
       "      <td>126.71786</td>\n",
       "      <td>126.94739</td>\n",
       "      <td>...</td>\n",
       "      <td>-99.309857</td>\n",
       "      <td>-2.551580</td>\n",
       "      <td>-47.104800</td>\n",
       "      <td>-4.057573</td>\n",
       "      <td>False</td>\n",
       "      <td>-9.798127e+06</td>\n",
       "      <td>-39.135081</td>\n",
       "      <td>-24.923630</td>\n",
       "      <td>0.907692</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-03 15:07:00+00:00</th>\n",
       "      <td>126.7100</td>\n",
       "      <td>126.870</td>\n",
       "      <td>126.5000</td>\n",
       "      <td>3189</td>\n",
       "      <td>126.580</td>\n",
       "      <td>289721</td>\n",
       "      <td>126.666956</td>\n",
       "      <td>0.001027</td>\n",
       "      <td>126.69186</td>\n",
       "      <td>126.87129</td>\n",
       "      <td>...</td>\n",
       "      <td>-88.964539</td>\n",
       "      <td>-2.402012</td>\n",
       "      <td>-38.479113</td>\n",
       "      <td>-3.693347</td>\n",
       "      <td>False</td>\n",
       "      <td>-9.594539e+06</td>\n",
       "      <td>-32.305140</td>\n",
       "      <td>-24.862300</td>\n",
       "      <td>0.792548</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-03 15:08:00+00:00</th>\n",
       "      <td>126.7066</td>\n",
       "      <td>126.760</td>\n",
       "      <td>126.5601</td>\n",
       "      <td>2861</td>\n",
       "      <td>126.705</td>\n",
       "      <td>255144</td>\n",
       "      <td>126.687038</td>\n",
       "      <td>-0.000027</td>\n",
       "      <td>126.66934</td>\n",
       "      <td>126.81495</td>\n",
       "      <td>...</td>\n",
       "      <td>-84.000283</td>\n",
       "      <td>-2.241145</td>\n",
       "      <td>-38.583764</td>\n",
       "      <td>-3.567436</td>\n",
       "      <td>False</td>\n",
       "      <td>-9.590454e+06</td>\n",
       "      <td>-32.682043</td>\n",
       "      <td>-24.646221</td>\n",
       "      <td>0.705603</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 97 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              close     high       low  trade_count     open  \\\n",
       "timestamp                                                                      \n",
       "2023-01-03 15:04:00+00:00  126.5001  126.880  126.4166         5733  126.820   \n",
       "2023-01-03 15:05:00+00:00  126.8500  126.895  126.4400         3763  126.505   \n",
       "2023-01-03 15:06:00+00:00  126.5800  126.870  126.5300         2930  126.860   \n",
       "2023-01-03 15:07:00+00:00  126.7100  126.870  126.5000         3189  126.580   \n",
       "2023-01-03 15:08:00+00:00  126.7066  126.760  126.5601         2861  126.705   \n",
       "\n",
       "                           volume        vwap  pct_returns       SMA5  \\\n",
       "timestamp                                                               \n",
       "2023-01-03 15:04:00+00:00  513722  126.624892    -0.002516  126.87386   \n",
       "2023-01-03 15:05:00+00:00  362900  126.625878     0.002766  126.80786   \n",
       "2023-01-03 15:06:00+00:00  240388  126.664497    -0.002128  126.71786   \n",
       "2023-01-03 15:07:00+00:00  289721  126.666956     0.001027  126.69186   \n",
       "2023-01-03 15:08:00+00:00  255144  126.687038    -0.000027  126.66934   \n",
       "\n",
       "                               SMA10  ...         CCI      COPP        CMO  \\\n",
       "timestamp                             ...                                    \n",
       "2023-01-03 15:04:00+00:00  127.15340  ... -116.423590 -2.878051 -65.583650   \n",
       "2023-01-03 15:05:00+00:00  127.06139  ... -101.126762 -2.719298 -40.134546   \n",
       "2023-01-03 15:06:00+00:00  126.94739  ...  -99.309857 -2.551580 -47.104800   \n",
       "2023-01-03 15:07:00+00:00  126.87129  ...  -88.964539 -2.402012 -38.479113   \n",
       "2023-01-03 15:08:00+00:00  126.81495  ...  -84.000283 -2.241145 -38.583764   \n",
       "\n",
       "                               FISH  SQZMI           VPT        FVE  \\\n",
       "timestamp                                                             \n",
       "2023-01-03 15:04:00+00:00 -4.458619  False -9.952525e+06 -43.838967   \n",
       "2023-01-03 15:05:00+00:00 -4.465828  False -9.402193e+06 -43.321203   \n",
       "2023-01-03 15:06:00+00:00 -4.057573  False -9.798127e+06 -39.135081   \n",
       "2023-01-03 15:07:00+00:00 -3.693347  False -9.594539e+06 -32.305140   \n",
       "2023-01-03 15:08:00+00:00 -3.567436  False -9.590454e+06 -32.682043   \n",
       "\n",
       "                                 VFI       MSD  STC  \n",
       "timestamp                                            \n",
       "2023-01-03 15:04:00+00:00 -25.409400  1.034633  0.0  \n",
       "2023-01-03 15:05:00+00:00 -24.707011  0.967187  0.0  \n",
       "2023-01-03 15:06:00+00:00 -24.923630  0.907692  0.0  \n",
       "2023-01-03 15:07:00+00:00 -24.862300  0.792548  0.0  \n",
       "2023-01-03 15:08:00+00:00 -24.646221  0.705603  0.0  \n",
       "\n",
       "[5 rows x 97 columns]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X is everything except the signal column\n",
    "X = df.drop('signal', axis=1)\n",
    "\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>close</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>trade_count</th>\n",
       "      <th>open</th>\n",
       "      <th>volume</th>\n",
       "      <th>vwap</th>\n",
       "      <th>pct_returns</th>\n",
       "      <th>SMA5</th>\n",
       "      <th>SMA10</th>\n",
       "      <th>...</th>\n",
       "      <th>CCI</th>\n",
       "      <th>COPP</th>\n",
       "      <th>CMO</th>\n",
       "      <th>FISH</th>\n",
       "      <th>SQZMI</th>\n",
       "      <th>VPT</th>\n",
       "      <th>FVE</th>\n",
       "      <th>VFI</th>\n",
       "      <th>MSD</th>\n",
       "      <th>STC</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-01-03 15:05:00+00:00</th>\n",
       "      <td>126.5001</td>\n",
       "      <td>126.880</td>\n",
       "      <td>126.4166</td>\n",
       "      <td>5733.0</td>\n",
       "      <td>126.820</td>\n",
       "      <td>513722.0</td>\n",
       "      <td>126.624892</td>\n",
       "      <td>-0.002516</td>\n",
       "      <td>126.87386</td>\n",
       "      <td>127.15340</td>\n",
       "      <td>...</td>\n",
       "      <td>-116.423590</td>\n",
       "      <td>-2.878051</td>\n",
       "      <td>-65.583650</td>\n",
       "      <td>-4.458619</td>\n",
       "      <td>False</td>\n",
       "      <td>-9.952525e+06</td>\n",
       "      <td>-43.838967</td>\n",
       "      <td>-25.409400</td>\n",
       "      <td>1.034633</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-03 15:06:00+00:00</th>\n",
       "      <td>126.8500</td>\n",
       "      <td>126.895</td>\n",
       "      <td>126.4400</td>\n",
       "      <td>3763.0</td>\n",
       "      <td>126.505</td>\n",
       "      <td>362900.0</td>\n",
       "      <td>126.625878</td>\n",
       "      <td>0.002766</td>\n",
       "      <td>126.80786</td>\n",
       "      <td>127.06139</td>\n",
       "      <td>...</td>\n",
       "      <td>-101.126762</td>\n",
       "      <td>-2.719298</td>\n",
       "      <td>-40.134546</td>\n",
       "      <td>-4.465828</td>\n",
       "      <td>False</td>\n",
       "      <td>-9.402193e+06</td>\n",
       "      <td>-43.321203</td>\n",
       "      <td>-24.707011</td>\n",
       "      <td>0.967187</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-03 15:07:00+00:00</th>\n",
       "      <td>126.5800</td>\n",
       "      <td>126.870</td>\n",
       "      <td>126.5300</td>\n",
       "      <td>2930.0</td>\n",
       "      <td>126.860</td>\n",
       "      <td>240388.0</td>\n",
       "      <td>126.664497</td>\n",
       "      <td>-0.002128</td>\n",
       "      <td>126.71786</td>\n",
       "      <td>126.94739</td>\n",
       "      <td>...</td>\n",
       "      <td>-99.309857</td>\n",
       "      <td>-2.551580</td>\n",
       "      <td>-47.104800</td>\n",
       "      <td>-4.057573</td>\n",
       "      <td>False</td>\n",
       "      <td>-9.798127e+06</td>\n",
       "      <td>-39.135081</td>\n",
       "      <td>-24.923630</td>\n",
       "      <td>0.907692</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-03 15:08:00+00:00</th>\n",
       "      <td>126.7100</td>\n",
       "      <td>126.870</td>\n",
       "      <td>126.5000</td>\n",
       "      <td>3189.0</td>\n",
       "      <td>126.580</td>\n",
       "      <td>289721.0</td>\n",
       "      <td>126.666956</td>\n",
       "      <td>0.001027</td>\n",
       "      <td>126.69186</td>\n",
       "      <td>126.87129</td>\n",
       "      <td>...</td>\n",
       "      <td>-88.964539</td>\n",
       "      <td>-2.402012</td>\n",
       "      <td>-38.479113</td>\n",
       "      <td>-3.693347</td>\n",
       "      <td>False</td>\n",
       "      <td>-9.594539e+06</td>\n",
       "      <td>-32.305140</td>\n",
       "      <td>-24.862300</td>\n",
       "      <td>0.792548</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-03 15:09:00+00:00</th>\n",
       "      <td>126.7066</td>\n",
       "      <td>126.760</td>\n",
       "      <td>126.5601</td>\n",
       "      <td>2861.0</td>\n",
       "      <td>126.705</td>\n",
       "      <td>255144.0</td>\n",
       "      <td>126.687038</td>\n",
       "      <td>-0.000027</td>\n",
       "      <td>126.66934</td>\n",
       "      <td>126.81495</td>\n",
       "      <td>...</td>\n",
       "      <td>-84.000283</td>\n",
       "      <td>-2.241145</td>\n",
       "      <td>-38.583764</td>\n",
       "      <td>-3.567436</td>\n",
       "      <td>False</td>\n",
       "      <td>-9.590454e+06</td>\n",
       "      <td>-32.682043</td>\n",
       "      <td>-24.646221</td>\n",
       "      <td>0.705603</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 97 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              close     high       low  trade_count     open  \\\n",
       "timestamp                                                                      \n",
       "2023-01-03 15:05:00+00:00  126.5001  126.880  126.4166       5733.0  126.820   \n",
       "2023-01-03 15:06:00+00:00  126.8500  126.895  126.4400       3763.0  126.505   \n",
       "2023-01-03 15:07:00+00:00  126.5800  126.870  126.5300       2930.0  126.860   \n",
       "2023-01-03 15:08:00+00:00  126.7100  126.870  126.5000       3189.0  126.580   \n",
       "2023-01-03 15:09:00+00:00  126.7066  126.760  126.5601       2861.0  126.705   \n",
       "\n",
       "                             volume        vwap  pct_returns       SMA5  \\\n",
       "timestamp                                                                 \n",
       "2023-01-03 15:05:00+00:00  513722.0  126.624892    -0.002516  126.87386   \n",
       "2023-01-03 15:06:00+00:00  362900.0  126.625878     0.002766  126.80786   \n",
       "2023-01-03 15:07:00+00:00  240388.0  126.664497    -0.002128  126.71786   \n",
       "2023-01-03 15:08:00+00:00  289721.0  126.666956     0.001027  126.69186   \n",
       "2023-01-03 15:09:00+00:00  255144.0  126.687038    -0.000027  126.66934   \n",
       "\n",
       "                               SMA10  ...         CCI      COPP        CMO  \\\n",
       "timestamp                             ...                                    \n",
       "2023-01-03 15:05:00+00:00  127.15340  ... -116.423590 -2.878051 -65.583650   \n",
       "2023-01-03 15:06:00+00:00  127.06139  ... -101.126762 -2.719298 -40.134546   \n",
       "2023-01-03 15:07:00+00:00  126.94739  ...  -99.309857 -2.551580 -47.104800   \n",
       "2023-01-03 15:08:00+00:00  126.87129  ...  -88.964539 -2.402012 -38.479113   \n",
       "2023-01-03 15:09:00+00:00  126.81495  ...  -84.000283 -2.241145 -38.583764   \n",
       "\n",
       "                               FISH  SQZMI           VPT        FVE  \\\n",
       "timestamp                                                             \n",
       "2023-01-03 15:05:00+00:00 -4.458619  False -9.952525e+06 -43.838967   \n",
       "2023-01-03 15:06:00+00:00 -4.465828  False -9.402193e+06 -43.321203   \n",
       "2023-01-03 15:07:00+00:00 -4.057573  False -9.798127e+06 -39.135081   \n",
       "2023-01-03 15:08:00+00:00 -3.693347  False -9.594539e+06 -32.305140   \n",
       "2023-01-03 15:09:00+00:00 -3.567436  False -9.590454e+06 -32.682043   \n",
       "\n",
       "                                 VFI       MSD  STC  \n",
       "timestamp                                            \n",
       "2023-01-03 15:05:00+00:00 -25.409400  1.034633  0.0  \n",
       "2023-01-03 15:06:00+00:00 -24.707011  0.967187  0.0  \n",
       "2023-01-03 15:07:00+00:00 -24.923630  0.907692  0.0  \n",
       "2023-01-03 15:08:00+00:00 -24.862300  0.792548  0.0  \n",
       "2023-01-03 15:09:00+00:00 -24.646221  0.705603  0.0  \n",
       "\n",
       "[5 rows x 97 columns]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We should use the .shift() function so that our algorithm predicts the minute before realtime\n",
    "# Drop the row with NaN values \n",
    "X = X.shift().dropna()\n",
    "\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We may look to consider what it would do if we changed the amount that we shifted by. Perhaps we tried predicting 5 minutes into the future... how about an hour?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "timestamp\n",
       "2023-01-03 15:04:00+00:00    0\n",
       "2023-01-03 15:05:00+00:00    0\n",
       "2023-01-03 15:06:00+00:00    0\n",
       "2023-01-03 15:07:00+00:00    0\n",
       "2023-01-03 15:08:00+00:00    0\n",
       "                            ..\n",
       "2024-01-17 00:47:00+00:00    0\n",
       "2024-01-17 00:52:00+00:00    0\n",
       "2024-01-17 00:55:00+00:00    0\n",
       "2024-01-17 00:57:00+00:00    0\n",
       "2024-01-17 00:58:00+00:00    0\n",
       "Name: signal, Length: 153682, dtype: int64"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y is the signal column\n",
    "y = df[(\"signal\")]\n",
    "\n",
    "y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-03 15:05:00+00:00\n"
     ]
    }
   ],
   "source": [
    "# Set start of training period\n",
    "training_begin = X.index.min()\n",
    "\n",
    "print(training_begin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-10-03 15:05:00+00:00\n"
     ]
    }
   ],
   "source": [
    "# Select ending period for the training data. Since we pulled a year's worth of data\n",
    "# we will train on 9 months and then test with the rest\n",
    "training_end = X.index.min() + DateOffset(months=9)\n",
    "\n",
    "print(training_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the X_train and y_train DataFrames\n",
    "X_train = X.loc[training_begin:training_end]\n",
    "y_train = y.loc[training_begin:training_end]\n",
    "\n",
    "# Generate the X_test and y_test DataFrames\n",
    "X_test = X.loc[training_end:]\n",
    "y_test = y.loc[training_end:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a StandardScaler instance\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Apply the scaler model to fit the X-train data\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Transform the X_train and X_test DataFrames using the X_scaler\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(113680, 97)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(40002, 97)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(X_train_scaled.shape)\n",
    "display(X_test_scaled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "# Use RandomOverSampler to resample the datase using random_state=1\n",
    "ros = RandomOverSampler(random_state=1)\n",
    "X_resampled, y_resampled = ros.fit_resample(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(113680, 97)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(40002, 97)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(X_train_scaled.shape)\n",
    "display(X_test_scaled.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now that we have scaled our data, we can build our neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_predictors = len(X.columns)\n",
    "\n",
    "# We have 3 possible outcomes, and we are trying to predict the stock/indicators to be in position -1, 0, or 1\n",
    "num_classes = 1\n",
    "\n",
    "num_predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/montygash/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/dense.py:73: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Add dense layer(s)\n",
    "nn_model.add(Dense(10, input_dim=num_predictors, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop-out layer(s)\n",
    "# nn_model.add(Dropout(.2,input_shape=(10,)))\n",
    "\n",
    "# Add dense layer, add Regularization\n",
    "#model.add(Dense(5, activation='relu', kernel_regularized=l2(0.01), bias_regularized=l2(0.01)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add output layer\n",
    "# Number of outputs equals number of classes\n",
    "#nn_model.add(Dense(num_classes))\n",
    "nn_model.add(Dense(num_classes, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_9\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_9\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">    Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━┩\n",
       "│ dense_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                │        <span style=\"color: #00af00; text-decoration-color: #00af00\">980</span> │\n",
       "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
       "│ dense_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span> │\n",
       "└─────────────────────────────────┴───────────────────────────┴────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━┩\n",
       "│ dense_19 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                │        \u001b[38;5;34m980\u001b[0m │\n",
       "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
       "│ dense_20 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                 │         \u001b[38;5;34m11\u001b[0m │\n",
       "└─────────────────────────────────┴───────────────────────────┴────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">991</span> (3.87 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m991\u001b[0m (3.87 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">991</span> (3.87 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m991\u001b[0m (3.87 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compile model\n",
    "nn_model.compile(loss=\"categorical_crossentropy\",\n",
    "              optimizer=\"adam\",\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Summarize model\n",
    "nn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/montygash/anaconda3/lib/python3.11/site-packages/keras/src/losses/losses.py:22: SyntaxWarning: In loss categorical_crossentropy, expected y_pred.shape to be (batch_size, num_classes) with num_classes > 1. Received: y_pred.shape=(None, 1). Consider using 'binary_crossentropy' if you only have 2 classes.\n",
      "  return self.fn(y_true, y_pred, **self._fn_kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 645us/step - accuracy: 0.1159 - loss: 0.0000e+00 - val_accuracy: 0.1138 - val_loss: 0.0000e+00\n",
      "Epoch 2/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 419us/step - accuracy: 0.1160 - loss: 0.0000e+00 - val_accuracy: 0.1138 - val_loss: 0.0000e+00\n",
      "Epoch 3/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 422us/step - accuracy: 0.1145 - loss: 0.0000e+00 - val_accuracy: 0.1138 - val_loss: 0.0000e+00\n",
      "Epoch 4/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 379us/step - accuracy: 0.1153 - loss: 0.0000e+00 - val_accuracy: 0.1138 - val_loss: 0.0000e+00\n",
      "Epoch 5/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 367us/step - accuracy: 0.1136 - loss: 0.0000e+00 - val_accuracy: 0.1138 - val_loss: 0.0000e+00\n",
      "Epoch 6/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 366us/step - accuracy: 0.1160 - loss: 0.0000e+00 - val_accuracy: 0.1138 - val_loss: 0.0000e+00\n",
      "Epoch 7/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 362us/step - accuracy: 0.1145 - loss: 0.0000e+00 - val_accuracy: 0.1138 - val_loss: 0.0000e+00\n",
      "Epoch 8/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414us/step - accuracy: 0.1146 - loss: 0.0000e+00 - val_accuracy: 0.1138 - val_loss: 0.0000e+00\n",
      "Epoch 9/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 372us/step - accuracy: 0.1143 - loss: 0.0000e+00 - val_accuracy: 0.1138 - val_loss: 0.0000e+00\n",
      "Epoch 10/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 392us/step - accuracy: 0.1160 - loss: 0.0000e+00 - val_accuracy: 0.1138 - val_loss: 0.0000e+00\n",
      "Epoch 11/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 423us/step - accuracy: 0.1165 - loss: 0.0000e+00 - val_accuracy: 0.1138 - val_loss: 0.0000e+00\n",
      "Epoch 12/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387us/step - accuracy: 0.1157 - loss: 0.0000e+00 - val_accuracy: 0.1138 - val_loss: 0.0000e+00\n",
      "Epoch 13/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390us/step - accuracy: 0.1156 - loss: 0.0000e+00 - val_accuracy: 0.1138 - val_loss: 0.0000e+00\n",
      "Epoch 14/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 461us/step - accuracy: 0.1127 - loss: 0.0000e+00 - val_accuracy: 0.1138 - val_loss: 0.0000e+00\n",
      "Epoch 15/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 379us/step - accuracy: 0.1160 - loss: 0.0000e+00 - val_accuracy: 0.1138 - val_loss: 0.0000e+00\n",
      "Epoch 16/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 937us/step - accuracy: 0.1154 - loss: 0.0000e+00 - val_accuracy: 0.1138 - val_loss: 0.0000e+00\n",
      "Epoch 17/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 416us/step - accuracy: 0.1150 - loss: 0.0000e+00 - val_accuracy: 0.1138 - val_loss: 0.0000e+00\n",
      "Epoch 18/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 377us/step - accuracy: 0.1143 - loss: 0.0000e+00 - val_accuracy: 0.1138 - val_loss: 0.0000e+00\n",
      "Epoch 19/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 440us/step - accuracy: 0.1134 - loss: 0.0000e+00 - val_accuracy: 0.1138 - val_loss: 0.0000e+00\n",
      "Epoch 20/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 392us/step - accuracy: 0.1153 - loss: 0.0000e+00 - val_accuracy: 0.1138 - val_loss: 0.0000e+00\n",
      "Epoch 21/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 392us/step - accuracy: 0.1169 - loss: 0.0000e+00 - val_accuracy: 0.1138 - val_loss: 0.0000e+00\n",
      "Epoch 22/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 420us/step - accuracy: 0.1143 - loss: 0.0000e+00 - val_accuracy: 0.1138 - val_loss: 0.0000e+00\n",
      "Epoch 23/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 367us/step - accuracy: 0.1155 - loss: 0.0000e+00 - val_accuracy: 0.1138 - val_loss: 0.0000e+00\n",
      "Epoch 24/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 367us/step - accuracy: 0.1152 - loss: 0.0000e+00 - val_accuracy: 0.1138 - val_loss: 0.0000e+00\n",
      "Epoch 25/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 418us/step - accuracy: 0.1153 - loss: 0.0000e+00 - val_accuracy: 0.1138 - val_loss: 0.0000e+00\n",
      "Epoch 26/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 373us/step - accuracy: 0.1169 - loss: 0.0000e+00 - val_accuracy: 0.1138 - val_loss: 0.0000e+00\n",
      "Epoch 27/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 382us/step - accuracy: 0.1150 - loss: 0.0000e+00 - val_accuracy: 0.1138 - val_loss: 0.0000e+00\n",
      "Epoch 28/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 431us/step - accuracy: 0.1179 - loss: 0.0000e+00 - val_accuracy: 0.1138 - val_loss: 0.0000e+00\n",
      "Epoch 29/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 379us/step - accuracy: 0.1143 - loss: 0.0000e+00 - val_accuracy: 0.1138 - val_loss: 0.0000e+00\n",
      "Epoch 30/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 386us/step - accuracy: 0.1155 - loss: 0.0000e+00 - val_accuracy: 0.1138 - val_loss: 0.0000e+00\n",
      "Epoch 31/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 400us/step - accuracy: 0.1137 - loss: 0.0000e+00 - val_accuracy: 0.1138 - val_loss: 0.0000e+00\n",
      "Epoch 32/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 386us/step - accuracy: 0.1144 - loss: 0.0000e+00 - val_accuracy: 0.1138 - val_loss: 0.0000e+00\n",
      "Epoch 33/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 371us/step - accuracy: 0.1145 - loss: 0.0000e+00 - val_accuracy: 0.1138 - val_loss: 0.0000e+00\n",
      "Epoch 34/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 490us/step - accuracy: 0.1151 - loss: 0.0000e+00 - val_accuracy: 0.1138 - val_loss: 0.0000e+00\n",
      "Epoch 35/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 381us/step - accuracy: 0.1152 - loss: 0.0000e+00 - val_accuracy: 0.1138 - val_loss: 0.0000e+00\n",
      "Epoch 36/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 408us/step - accuracy: 0.1160 - loss: 0.0000e+00 - val_accuracy: 0.1138 - val_loss: 0.0000e+00\n",
      "Epoch 37/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 371us/step - accuracy: 0.1157 - loss: 0.0000e+00 - val_accuracy: 0.1138 - val_loss: 0.0000e+00\n",
      "Epoch 38/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 518us/step - accuracy: 0.1143 - loss: 0.0000e+00 - val_accuracy: 0.1138 - val_loss: 0.0000e+00\n",
      "Epoch 39/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 411us/step - accuracy: 0.1165 - loss: 0.0000e+00 - val_accuracy: 0.1138 - val_loss: 0.0000e+00\n",
      "Epoch 40/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 382us/step - accuracy: 0.1158 - loss: 0.0000e+00 - val_accuracy: 0.1138 - val_loss: 0.0000e+00\n",
      "Epoch 41/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 398us/step - accuracy: 0.1139 - loss: 0.0000e+00 - val_accuracy: 0.1138 - val_loss: 0.0000e+00\n",
      "Epoch 42/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 466us/step - accuracy: 0.1144 - loss: 0.0000e+00 - val_accuracy: 0.1138 - val_loss: 0.0000e+00\n",
      "Epoch 43/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 369us/step - accuracy: 0.1161 - loss: 0.0000e+00 - val_accuracy: 0.1138 - val_loss: 0.0000e+00\n",
      "Epoch 44/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 367us/step - accuracy: 0.1153 - loss: 0.0000e+00 - val_accuracy: 0.1138 - val_loss: 0.0000e+00\n",
      "Epoch 45/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 422us/step - accuracy: 0.1161 - loss: 0.0000e+00 - val_accuracy: 0.1138 - val_loss: 0.0000e+00\n",
      "Epoch 46/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 386us/step - accuracy: 0.1152 - loss: 0.0000e+00 - val_accuracy: 0.1138 - val_loss: 0.0000e+00\n",
      "Epoch 47/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 369us/step - accuracy: 0.1149 - loss: 0.0000e+00 - val_accuracy: 0.1138 - val_loss: 0.0000e+00\n",
      "Epoch 48/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 443us/step - accuracy: 0.1149 - loss: 0.0000e+00 - val_accuracy: 0.1138 - val_loss: 0.0000e+00\n",
      "Epoch 49/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 401us/step - accuracy: 0.1153 - loss: 0.0000e+00 - val_accuracy: 0.1138 - val_loss: 0.0000e+00\n",
      "Epoch 50/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 446us/step - accuracy: 0.1155 - loss: 0.0000e+00 - val_accuracy: 0.1138 - val_loss: 0.0000e+00\n",
      "Epoch 51/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 394us/step - accuracy: 0.1147 - loss: 0.0000e+00 - val_accuracy: 0.1138 - val_loss: 0.0000e+00\n",
      "Epoch 52/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 378us/step - accuracy: 0.1157 - loss: 0.0000e+00 - val_accuracy: 0.1138 - val_loss: 0.0000e+00\n",
      "Epoch 53/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 450us/step - accuracy: 0.1165 - loss: 0.0000e+00 - val_accuracy: 0.1138 - val_loss: 0.0000e+00\n",
      "Epoch 54/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 381us/step - accuracy: 0.1165 - loss: 0.0000e+00 - val_accuracy: 0.1138 - val_loss: 0.0000e+00\n",
      "Epoch 55/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 358us/step - accuracy: 0.1158 - loss: 0.0000e+00 - val_accuracy: 0.1138 - val_loss: 0.0000e+00\n",
      "Epoch 56/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 405us/step - accuracy: 0.1143 - loss: 0.0000e+00 - val_accuracy: 0.1138 - val_loss: 0.0000e+00\n",
      "Epoch 57/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 370us/step - accuracy: 0.1154 - loss: 0.0000e+00 - val_accuracy: 0.1138 - val_loss: 0.0000e+00\n",
      "Epoch 58/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 374us/step - accuracy: 0.1159 - loss: 0.0000e+00 - val_accuracy: 0.1138 - val_loss: 0.0000e+00\n",
      "Epoch 59/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 440us/step - accuracy: 0.1141 - loss: 0.0000e+00 - val_accuracy: 0.1138 - val_loss: 0.0000e+00\n",
      "Epoch 60/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 563us/step - accuracy: 0.1167 - loss: 0.0000e+00 - val_accuracy: 0.1138 - val_loss: 0.0000e+00\n",
      "Epoch 61/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 418us/step - accuracy: 0.1163 - loss: 0.0000e+00 - val_accuracy: 0.1138 - val_loss: 0.0000e+00\n",
      "Epoch 62/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 397us/step - accuracy: 0.1157 - loss: 0.0000e+00 - val_accuracy: 0.1138 - val_loss: 0.0000e+00\n",
      "Epoch 63/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 374us/step - accuracy: 0.1149 - loss: 0.0000e+00 - val_accuracy: 0.1138 - val_loss: 0.0000e+00\n",
      "Epoch 64/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 430us/step - accuracy: 0.1173 - loss: 0.0000e+00 - val_accuracy: 0.1138 - val_loss: 0.0000e+00\n",
      "Epoch 65/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 363us/step - accuracy: 0.1150 - loss: 0.0000e+00 - val_accuracy: 0.1138 - val_loss: 0.0000e+00\n",
      "Epoch 66/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 410us/step - accuracy: 0.1155 - loss: 0.0000e+00 - val_accuracy: 0.1138 - val_loss: 0.0000e+00\n",
      "Epoch 67/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 440us/step - accuracy: 0.1147 - loss: 0.0000e+00 - val_accuracy: 0.1138 - val_loss: 0.0000e+00\n",
      "Epoch 68/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 361us/step - accuracy: 0.1158 - loss: 0.0000e+00 - val_accuracy: 0.1138 - val_loss: 0.0000e+00\n",
      "Epoch 69/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 376us/step - accuracy: 0.1152 - loss: 0.0000e+00 - val_accuracy: 0.1138 - val_loss: 0.0000e+00\n",
      "Epoch 70/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 379us/step - accuracy: 0.1139 - loss: 0.0000e+00 - val_accuracy: 0.1138 - val_loss: 0.0000e+00\n",
      "Epoch 71/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 369us/step - accuracy: 0.1139 - loss: 0.0000e+00 - val_accuracy: 0.1138 - val_loss: 0.0000e+00\n",
      "Epoch 72/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 341us/step - accuracy: 0.1172 - loss: 0.0000e+00 - val_accuracy: 0.1138 - val_loss: 0.0000e+00\n",
      "Epoch 73/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 391us/step - accuracy: 0.1147 - loss: 0.0000e+00 - val_accuracy: 0.1138 - val_loss: 0.0000e+00\n",
      "Epoch 74/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 341us/step - accuracy: 0.1150 - loss: 0.0000e+00 - val_accuracy: 0.1138 - val_loss: 0.0000e+00\n",
      "Epoch 75/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 345us/step - accuracy: 0.1156 - loss: 0.0000e+00 - val_accuracy: 0.1138 - val_loss: 0.0000e+00\n",
      "Epoch 76/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 341us/step - accuracy: 0.1150 - loss: 0.0000e+00 - val_accuracy: 0.1138 - val_loss: 0.0000e+00\n",
      "Epoch 77/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387us/step - accuracy: 0.1157 - loss: 0.0000e+00 - val_accuracy: 0.1138 - val_loss: 0.0000e+00\n",
      "Epoch 78/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 340us/step - accuracy: 0.1135 - loss: 0.0000e+00 - val_accuracy: 0.1138 - val_loss: 0.0000e+00\n",
      "Epoch 79/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 344us/step - accuracy: 0.1142 - loss: 0.0000e+00 - val_accuracy: 0.1138 - val_loss: 0.0000e+00\n",
      "Epoch 80/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - accuracy: 0.1142 - loss: 0.0000e+00 - val_accuracy: 0.1138 - val_loss: 0.0000e+00\n",
      "Epoch 81/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 353us/step - accuracy: 0.1162 - loss: 0.0000e+00 - val_accuracy: 0.1138 - val_loss: 0.0000e+00\n",
      "Epoch 82/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 340us/step - accuracy: 0.1146 - loss: 0.0000e+00 - val_accuracy: 0.1138 - val_loss: 0.0000e+00\n",
      "Epoch 83/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390us/step - accuracy: 0.1142 - loss: 0.0000e+00 - val_accuracy: 0.1138 - val_loss: 0.0000e+00\n",
      "Epoch 84/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 344us/step - accuracy: 0.1158 - loss: 0.0000e+00 - val_accuracy: 0.1138 - val_loss: 0.0000e+00\n",
      "Epoch 85/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 341us/step - accuracy: 0.1149 - loss: 0.0000e+00 - val_accuracy: 0.1138 - val_loss: 0.0000e+00\n",
      "Epoch 86/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 343us/step - accuracy: 0.1152 - loss: 0.0000e+00 - val_accuracy: 0.1138 - val_loss: 0.0000e+00\n",
      "Epoch 87/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 376us/step - accuracy: 0.1146 - loss: 0.0000e+00 - val_accuracy: 0.1138 - val_loss: 0.0000e+00\n",
      "Epoch 88/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 342us/step - accuracy: 0.1165 - loss: 0.0000e+00 - val_accuracy: 0.1138 - val_loss: 0.0000e+00\n",
      "Epoch 89/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 350us/step - accuracy: 0.1139 - loss: 0.0000e+00 - val_accuracy: 0.1138 - val_loss: 0.0000e+00\n",
      "Epoch 90/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 552us/step - accuracy: 0.1152 - loss: 0.0000e+00 - val_accuracy: 0.1138 - val_loss: 0.0000e+00\n",
      "Epoch 91/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 378us/step - accuracy: 0.1158 - loss: 0.0000e+00 - val_accuracy: 0.1138 - val_loss: 0.0000e+00\n",
      "Epoch 92/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 354us/step - accuracy: 0.1150 - loss: 0.0000e+00 - val_accuracy: 0.1138 - val_loss: 0.0000e+00\n",
      "Epoch 93/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 384us/step - accuracy: 0.1155 - loss: 0.0000e+00 - val_accuracy: 0.1138 - val_loss: 0.0000e+00\n",
      "Epoch 94/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 343us/step - accuracy: 0.1146 - loss: 0.0000e+00 - val_accuracy: 0.1138 - val_loss: 0.0000e+00\n",
      "Epoch 95/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 342us/step - accuracy: 0.1155 - loss: 0.0000e+00 - val_accuracy: 0.1138 - val_loss: 0.0000e+00\n",
      "Epoch 96/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 433us/step - accuracy: 0.1159 - loss: 0.0000e+00 - val_accuracy: 0.1138 - val_loss: 0.0000e+00\n",
      "Epoch 97/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 350us/step - accuracy: 0.1143 - loss: 0.0000e+00 - val_accuracy: 0.1138 - val_loss: 0.0000e+00\n",
      "Epoch 98/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 396us/step - accuracy: 0.1144 - loss: 0.0000e+00 - val_accuracy: 0.1138 - val_loss: 0.0000e+00\n",
      "Epoch 99/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 469us/step - accuracy: 0.1146 - loss: 0.0000e+00 - val_accuracy: 0.1138 - val_loss: 0.0000e+00\n",
      "Epoch 100/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 401us/step - accuracy: 0.1128 - loss: 0.0000e+00 - val_accuracy: 0.1138 - val_loss: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1687215d0>"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit model\n",
    "num_epochs = 100\n",
    "\n",
    "nn_model.fit(X_train_scaled, y_train,\n",
    "          epochs=num_epochs,\n",
    "          batch_size=100,\n",
    "          validation_split=0.2,     # This 'validation_split' is telling the neural network to keep 20% of the data to validate its score on the training set... this is to help AVOID OVERFITTING. \n",
    "          shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1251/1251 - 0s - 283us/step - accuracy: 0.1130 - loss: 0.0000e+00\n",
      "Loss: 0.0, Accuracy: 0.11304435133934021\n"
     ]
    }
   ],
   "source": [
    "# Show model loss and accuracy\n",
    "\n",
    "# Evaluate the model loss and accuracy metrics using the evaluate method and the test data\n",
    "model_loss, model_accuracy = nn_model.evaluate(X_test_scaled, y_test, verbose=2)\n",
    "\n",
    "# Display the evaluation results\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we backtest with the TEST portion of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1251/1251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 232us/step\n",
      "\u001b[1m3553/3553\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 227us/step\n"
     ]
    }
   ],
   "source": [
    "# Predict values using testing data\n",
    "nn_test_predictions = nn_model.predict(X_test_scaled)\n",
    "nn_train_predictions = nn_model.predict(X_train_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Evaluate the model using a classification report\n",
    "# from sklearn.metrics import classification_report\n",
    "# training_report = classification_report(nn_train_predictions, nn_test_predictions)\n",
    "# print(training_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Evaluate the model's ability to predict the trading signal for the testing data using a classification report\n",
    "# training_report = classification_report(y_test, testing_signal_predictions)\n",
    "# print(training_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save model history for further manipulation\n",
    "# model_history = model.history.model_history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Now we can plot the accuracy for training and validation\n",
    "\n",
    "# training_results = pd.DataFrame(index=range(1, num_epochs+1))\n",
    "# training_results['Training'] = model_history['categorical_accuracy']\n",
    "# training_results['Validation'] = model_history['val_categorical_accuracy']\n",
    "# training_results.plot(title = 'Training and Validation Performance')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now using the 3 minute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>close</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>trade_count</th>\n",
       "      <th>open</th>\n",
       "      <th>volume</th>\n",
       "      <th>vwap</th>\n",
       "      <th>pct_returns</th>\n",
       "      <th>SMA5</th>\n",
       "      <th>...</th>\n",
       "      <th>COPP</th>\n",
       "      <th>CMO</th>\n",
       "      <th>FISH</th>\n",
       "      <th>SQZMI</th>\n",
       "      <th>VPT</th>\n",
       "      <th>FVE</th>\n",
       "      <th>VFI</th>\n",
       "      <th>MSD</th>\n",
       "      <th>STC</th>\n",
       "      <th>signal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-01-04 00:12:00+00:00</td>\n",
       "      <td>124.95</td>\n",
       "      <td>124.96</td>\n",
       "      <td>124.95</td>\n",
       "      <td>92</td>\n",
       "      <td>124.96</td>\n",
       "      <td>3977</td>\n",
       "      <td>124.952526</td>\n",
       "      <td>-0.00024</td>\n",
       "      <td>124.974</td>\n",
       "      <td>...</td>\n",
       "      <td>0.070644</td>\n",
       "      <td>-1.427075</td>\n",
       "      <td>1.439150</td>\n",
       "      <td>False</td>\n",
       "      <td>-5.103025e+07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.639625</td>\n",
       "      <td>0.031817</td>\n",
       "      <td>99.378906</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-01-04 00:15:00+00:00</td>\n",
       "      <td>124.96</td>\n",
       "      <td>124.96</td>\n",
       "      <td>124.95</td>\n",
       "      <td>83</td>\n",
       "      <td>124.95</td>\n",
       "      <td>2583</td>\n",
       "      <td>124.949560</td>\n",
       "      <td>0.00008</td>\n",
       "      <td>124.970</td>\n",
       "      <td>...</td>\n",
       "      <td>0.059256</td>\n",
       "      <td>5.886957</td>\n",
       "      <td>1.047844</td>\n",
       "      <td>False</td>\n",
       "      <td>-5.102509e+07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.663836</td>\n",
       "      <td>0.027480</td>\n",
       "      <td>98.040465</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-01-04 00:18:00+00:00</td>\n",
       "      <td>124.97</td>\n",
       "      <td>124.97</td>\n",
       "      <td>124.96</td>\n",
       "      <td>56</td>\n",
       "      <td>124.96</td>\n",
       "      <td>765</td>\n",
       "      <td>124.962646</td>\n",
       "      <td>0.00008</td>\n",
       "      <td>124.968</td>\n",
       "      <td>...</td>\n",
       "      <td>0.057214</td>\n",
       "      <td>12.868265</td>\n",
       "      <td>0.858268</td>\n",
       "      <td>False</td>\n",
       "      <td>-5.102356e+07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.360573</td>\n",
       "      <td>0.024794</td>\n",
       "      <td>96.496636</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-01-04 00:21:00+00:00</td>\n",
       "      <td>125.03</td>\n",
       "      <td>125.10</td>\n",
       "      <td>124.98</td>\n",
       "      <td>128</td>\n",
       "      <td>124.98</td>\n",
       "      <td>11318</td>\n",
       "      <td>125.033116</td>\n",
       "      <td>0.00048</td>\n",
       "      <td>124.978</td>\n",
       "      <td>...</td>\n",
       "      <td>0.073006</td>\n",
       "      <td>41.699712</td>\n",
       "      <td>1.045054</td>\n",
       "      <td>False</td>\n",
       "      <td>-5.101413e+07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.359419</td>\n",
       "      <td>0.026735</td>\n",
       "      <td>96.194995</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-01-04 00:24:00+00:00</td>\n",
       "      <td>125.05</td>\n",
       "      <td>125.05</td>\n",
       "      <td>125.02</td>\n",
       "      <td>38</td>\n",
       "      <td>125.04</td>\n",
       "      <td>1088</td>\n",
       "      <td>125.043639</td>\n",
       "      <td>0.00016</td>\n",
       "      <td>124.992</td>\n",
       "      <td>...</td>\n",
       "      <td>0.083011</td>\n",
       "      <td>48.064587</td>\n",
       "      <td>1.318566</td>\n",
       "      <td>False</td>\n",
       "      <td>-5.101340e+07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.669126</td>\n",
       "      <td>0.032957</td>\n",
       "      <td>97.328048</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 99 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   timestamp   close    high     low  trade_count    open  \\\n",
       "0  2023-01-04 00:12:00+00:00  124.95  124.96  124.95           92  124.96   \n",
       "1  2023-01-04 00:15:00+00:00  124.96  124.96  124.95           83  124.95   \n",
       "2  2023-01-04 00:18:00+00:00  124.97  124.97  124.96           56  124.96   \n",
       "3  2023-01-04 00:21:00+00:00  125.03  125.10  124.98          128  124.98   \n",
       "4  2023-01-04 00:24:00+00:00  125.05  125.05  125.02           38  125.04   \n",
       "\n",
       "   volume        vwap  pct_returns     SMA5  ...      COPP        CMO  \\\n",
       "0    3977  124.952526     -0.00024  124.974  ...  0.070644  -1.427075   \n",
       "1    2583  124.949560      0.00008  124.970  ...  0.059256   5.886957   \n",
       "2     765  124.962646      0.00008  124.968  ...  0.057214  12.868265   \n",
       "3   11318  125.033116      0.00048  124.978  ...  0.073006  41.699712   \n",
       "4    1088  125.043639      0.00016  124.992  ...  0.083011  48.064587   \n",
       "\n",
       "       FISH  SQZMI           VPT  FVE       VFI       MSD        STC  signal  \n",
       "0  1.439150  False -5.103025e+07  0.0  5.639625  0.031817  99.378906       0  \n",
       "1  1.047844  False -5.102509e+07  0.0  5.663836  0.027480  98.040465       0  \n",
       "2  0.858268  False -5.102356e+07  0.0  6.360573  0.024794  96.496636       0  \n",
       "3  1.045054  False -5.101413e+07  0.0  6.359419  0.026735  96.194995       0  \n",
       "4  1.318566  False -5.101340e+07  0.0  6.669126  0.032957  97.328048       0  \n",
       "\n",
       "[5 rows x 99 columns]"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import indicator dataframe\n",
    "df = pd.read_csv(\"../algotrader2/resources/aapl_3min_pivot_point_indicator_df.csv\")\n",
    "df.head()\n",
    "\n",
    "# df = pd.read_csv(\"../algotrader2/resources/aapl_1min_pivot_point_indicator_df.csv\")\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>close</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>trade_count</th>\n",
       "      <th>open</th>\n",
       "      <th>volume</th>\n",
       "      <th>vwap</th>\n",
       "      <th>pct_returns</th>\n",
       "      <th>SMA5</th>\n",
       "      <th>SMA10</th>\n",
       "      <th>...</th>\n",
       "      <th>CCI</th>\n",
       "      <th>COPP</th>\n",
       "      <th>CMO</th>\n",
       "      <th>FISH</th>\n",
       "      <th>SQZMI</th>\n",
       "      <th>VPT</th>\n",
       "      <th>FVE</th>\n",
       "      <th>VFI</th>\n",
       "      <th>MSD</th>\n",
       "      <th>STC</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-01-04 00:15:00+00:00</th>\n",
       "      <td>124.95</td>\n",
       "      <td>124.96</td>\n",
       "      <td>124.95</td>\n",
       "      <td>92.0</td>\n",
       "      <td>124.96</td>\n",
       "      <td>3977.0</td>\n",
       "      <td>124.952526</td>\n",
       "      <td>-0.00024</td>\n",
       "      <td>124.974</td>\n",
       "      <td>124.964</td>\n",
       "      <td>...</td>\n",
       "      <td>41.437189</td>\n",
       "      <td>0.070644</td>\n",
       "      <td>-1.427075</td>\n",
       "      <td>1.439150</td>\n",
       "      <td>False</td>\n",
       "      <td>-5.103025e+07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.639625</td>\n",
       "      <td>0.031817</td>\n",
       "      <td>99.378906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-04 00:18:00+00:00</th>\n",
       "      <td>124.96</td>\n",
       "      <td>124.96</td>\n",
       "      <td>124.95</td>\n",
       "      <td>83.0</td>\n",
       "      <td>124.95</td>\n",
       "      <td>2583.0</td>\n",
       "      <td>124.949560</td>\n",
       "      <td>0.00008</td>\n",
       "      <td>124.970</td>\n",
       "      <td>124.965</td>\n",
       "      <td>...</td>\n",
       "      <td>44.639597</td>\n",
       "      <td>0.059256</td>\n",
       "      <td>5.886957</td>\n",
       "      <td>1.047844</td>\n",
       "      <td>False</td>\n",
       "      <td>-5.102509e+07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.663836</td>\n",
       "      <td>0.027480</td>\n",
       "      <td>98.040465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-04 00:21:00+00:00</th>\n",
       "      <td>124.97</td>\n",
       "      <td>124.97</td>\n",
       "      <td>124.96</td>\n",
       "      <td>56.0</td>\n",
       "      <td>124.96</td>\n",
       "      <td>765.0</td>\n",
       "      <td>124.962646</td>\n",
       "      <td>0.00008</td>\n",
       "      <td>124.968</td>\n",
       "      <td>124.967</td>\n",
       "      <td>...</td>\n",
       "      <td>72.955382</td>\n",
       "      <td>0.057214</td>\n",
       "      <td>12.868265</td>\n",
       "      <td>0.858268</td>\n",
       "      <td>False</td>\n",
       "      <td>-5.102356e+07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.360573</td>\n",
       "      <td>0.024794</td>\n",
       "      <td>96.496636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-04 00:24:00+00:00</th>\n",
       "      <td>125.03</td>\n",
       "      <td>125.10</td>\n",
       "      <td>124.98</td>\n",
       "      <td>128.0</td>\n",
       "      <td>124.98</td>\n",
       "      <td>11318.0</td>\n",
       "      <td>125.033116</td>\n",
       "      <td>0.00048</td>\n",
       "      <td>124.978</td>\n",
       "      <td>124.974</td>\n",
       "      <td>...</td>\n",
       "      <td>277.757872</td>\n",
       "      <td>0.073006</td>\n",
       "      <td>41.699712</td>\n",
       "      <td>1.045054</td>\n",
       "      <td>False</td>\n",
       "      <td>-5.101413e+07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.359419</td>\n",
       "      <td>0.026735</td>\n",
       "      <td>96.194995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-04 00:27:00+00:00</th>\n",
       "      <td>125.05</td>\n",
       "      <td>125.05</td>\n",
       "      <td>125.02</td>\n",
       "      <td>38.0</td>\n",
       "      <td>125.04</td>\n",
       "      <td>1088.0</td>\n",
       "      <td>125.043639</td>\n",
       "      <td>0.00016</td>\n",
       "      <td>124.992</td>\n",
       "      <td>124.984</td>\n",
       "      <td>...</td>\n",
       "      <td>231.408886</td>\n",
       "      <td>0.083011</td>\n",
       "      <td>48.064587</td>\n",
       "      <td>1.318566</td>\n",
       "      <td>False</td>\n",
       "      <td>-5.101340e+07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.669126</td>\n",
       "      <td>0.032957</td>\n",
       "      <td>97.328048</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 97 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            close    high     low  trade_count    open  \\\n",
       "timestamp                                                                \n",
       "2023-01-04 00:15:00+00:00  124.95  124.96  124.95         92.0  124.96   \n",
       "2023-01-04 00:18:00+00:00  124.96  124.96  124.95         83.0  124.95   \n",
       "2023-01-04 00:21:00+00:00  124.97  124.97  124.96         56.0  124.96   \n",
       "2023-01-04 00:24:00+00:00  125.03  125.10  124.98        128.0  124.98   \n",
       "2023-01-04 00:27:00+00:00  125.05  125.05  125.02         38.0  125.04   \n",
       "\n",
       "                            volume        vwap  pct_returns     SMA5    SMA10  \\\n",
       "timestamp                                                                       \n",
       "2023-01-04 00:15:00+00:00   3977.0  124.952526     -0.00024  124.974  124.964   \n",
       "2023-01-04 00:18:00+00:00   2583.0  124.949560      0.00008  124.970  124.965   \n",
       "2023-01-04 00:21:00+00:00    765.0  124.962646      0.00008  124.968  124.967   \n",
       "2023-01-04 00:24:00+00:00  11318.0  125.033116      0.00048  124.978  124.974   \n",
       "2023-01-04 00:27:00+00:00   1088.0  125.043639      0.00016  124.992  124.984   \n",
       "\n",
       "                           ...         CCI      COPP        CMO      FISH  \\\n",
       "timestamp                  ...                                              \n",
       "2023-01-04 00:15:00+00:00  ...   41.437189  0.070644  -1.427075  1.439150   \n",
       "2023-01-04 00:18:00+00:00  ...   44.639597  0.059256   5.886957  1.047844   \n",
       "2023-01-04 00:21:00+00:00  ...   72.955382  0.057214  12.868265  0.858268   \n",
       "2023-01-04 00:24:00+00:00  ...  277.757872  0.073006  41.699712  1.045054   \n",
       "2023-01-04 00:27:00+00:00  ...  231.408886  0.083011  48.064587  1.318566   \n",
       "\n",
       "                           SQZMI           VPT  FVE       VFI       MSD  \\\n",
       "timestamp                                                                 \n",
       "2023-01-04 00:15:00+00:00  False -5.103025e+07  0.0  5.639625  0.031817   \n",
       "2023-01-04 00:18:00+00:00  False -5.102509e+07  0.0  5.663836  0.027480   \n",
       "2023-01-04 00:21:00+00:00  False -5.102356e+07  0.0  6.360573  0.024794   \n",
       "2023-01-04 00:24:00+00:00  False -5.101413e+07  0.0  6.359419  0.026735   \n",
       "2023-01-04 00:27:00+00:00  False -5.101340e+07  0.0  6.669126  0.032957   \n",
       "\n",
       "                                 STC  \n",
       "timestamp                             \n",
       "2023-01-04 00:15:00+00:00  99.378906  \n",
       "2023-01-04 00:18:00+00:00  98.040465  \n",
       "2023-01-04 00:21:00+00:00  96.496636  \n",
       "2023-01-04 00:24:00+00:00  96.194995  \n",
       "2023-01-04 00:27:00+00:00  97.328048  \n",
       "\n",
       "[5 rows x 97 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start date: 2023-01-04 00:15:00+00:00\n",
      "End date: 2023-10-04 00:15:00+00:00\n"
     ]
    }
   ],
   "source": [
    "# Create our timestamp column as a datetime index, then save it as our index\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "df.set_index('timestamp', inplace=True)\n",
    "# X is everything except the signal column\n",
    "X = df.drop('signal', axis=1)\n",
    "# We should use the .shift() function so that our algorithm predicts the minute before realtime\n",
    "# Drop the row with NaN values \n",
    "X = X.shift().dropna()\n",
    "display(X.head())\n",
    "y = df[(\"signal\")]\n",
    "# Set start of training period\n",
    "training_begin = X.index.min()\n",
    "print(f\"Start date: {training_begin}\")\n",
    "# Select ending period for the training data. Since we pulled a year's worth of data\n",
    "# we will train on 9 months and then test with the rest\n",
    "training_end = X.index.min() + DateOffset(months=9)\n",
    "print(f\"End date: {training_end}\")\n",
    "# Generate the X_train and y_train DataFrames\n",
    "X_train = X.loc[training_begin:training_end]\n",
    "y_train = y.loc[training_begin:training_end]\n",
    "\n",
    "# Generate the X_test and y_test DataFrames\n",
    "X_test = X.loc[training_end:]\n",
    "y_test = y.loc[training_end:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(47724, 97)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(16982, 97)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(47724, 97)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(16982, 97)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a StandardScaler instance\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Apply the scaler model to fit the X-train data\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Transform the X_train and X_test DataFrames using the X_scaler\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)\n",
    "\n",
    "display(X_train_scaled.shape)\n",
    "display(X_test_scaled.shape)\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "# Use RandomOverSampler to resample the datase using random_state=1\n",
    "ros = RandomOverSampler(random_state=1)\n",
    "X_resampled, y_resampled = ros.fit_resample(X_train_scaled, y_train)\n",
    "display(X_train_scaled.shape)\n",
    "display(X_test_scaled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NEURAL NETWORK\n",
    "num_predictors = len(X.columns)\n",
    "num_classes = 1\n",
    "nn_model = Sequential()\n",
    "# Add dense layer(s)\n",
    "nn_model.add(Dense(10, input_dim=num_predictors, activation='relu'))\n",
    "# Drop-out layer(s)\n",
    "# nn_model.add(Dropout(.2,input_shape=(10,)))\n",
    "# Add dense layer, add Regularization\n",
    "#model.add(Dense(5, activation='relu', kernel_regularized=l2(0.01), bias_regularized=l2(0.01)))\n",
    "# Add output layer\n",
    "# Number of outputs equals number of classes\n",
    "#nn_model.add(Dense(num_classes))\n",
    "nn_model.add(Dense(num_classes, activation=\"softmax\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_12\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_12\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">    Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━┩\n",
       "│ dense_25 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                │        <span style=\"color: #00af00; text-decoration-color: #00af00\">980</span> │\n",
       "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
       "│ dense_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span> │\n",
       "└─────────────────────────────────┴───────────────────────────┴────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━┩\n",
       "│ dense_25 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                │        \u001b[38;5;34m980\u001b[0m │\n",
       "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
       "│ dense_26 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                 │         \u001b[38;5;34m11\u001b[0m │\n",
       "└─────────────────────────────────┴───────────────────────────┴────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">991</span> (3.87 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m991\u001b[0m (3.87 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">991</span> (3.87 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m991\u001b[0m (3.87 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compile model\n",
    "nn_model.compile(loss=\"categorical_crossentropy\",\n",
    "              optimizer=\"adam\",\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Summarize model\n",
    "nn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/montygash/anaconda3/lib/python3.11/site-packages/keras/src/losses/losses.py:22: SyntaxWarning: In loss categorical_crossentropy, expected y_pred.shape to be (batch_size, num_classes) with num_classes > 1. Received: y_pred.shape=(None, 1). Consider using 'binary_crossentropy' if you only have 2 classes.\n",
      "  return self.fn(y_true, y_pred, **self._fn_kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 426us/step - accuracy: 0.1149 - loss: 0.0000e+00 - val_accuracy: 0.1138 - val_loss: 0.0000e+00\n",
      "Epoch 2/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 350us/step - accuracy: 0.1150 - loss: 0.0000e+00 - val_accuracy: 0.1138 - val_loss: 0.0000e+00\n",
      "Epoch 3/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 346us/step - accuracy: 0.1154 - loss: 0.0000e+00 - val_accuracy: 0.1138 - val_loss: 0.0000e+00\n",
      "Epoch 4/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 400us/step - accuracy: 0.1152 - loss: 0.0000e+00 - val_accuracy: 0.1138 - val_loss: 0.0000e+00\n",
      "Epoch 5/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 360us/step - accuracy: 0.1147 - loss: 0.0000e+00 - val_accuracy: 0.1138 - val_loss: 0.0000e+00\n",
      "Epoch 6/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 396us/step - accuracy: 0.1142 - loss: 0.0000e+00 - val_accuracy: 0.1138 - val_loss: 0.0000e+00\n",
      "Epoch 7/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 396us/step - accuracy: 0.1138 - loss: 0.0000e+00 - val_accuracy: 0.1138 - val_loss: 0.0000e+00\n",
      "Epoch 8/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 347us/step - accuracy: 0.1147 - loss: 0.0000e+00 - val_accuracy: 0.1138 - val_loss: 0.0000e+00\n",
      "Epoch 9/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - accuracy: 0.1173 - loss: 0.0000e+00 - val_accuracy: 0.1138 - val_loss: 0.0000e+00\n",
      "Epoch 10/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 404us/step - accuracy: 0.1142 - loss: 0.0000e+00 - val_accuracy: 0.1138 - val_loss: 0.0000e+00\n",
      "Epoch 11/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 344us/step - accuracy: 0.1169 - loss: 0.0000e+00 - val_accuracy: 0.1138 - val_loss: 0.0000e+00\n",
      "Epoch 12/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 346us/step - accuracy: 0.1167 - loss: 0.0000e+00 - val_accuracy: 0.1138 - val_loss: 0.0000e+00\n",
      "Epoch 13/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 480us/step - accuracy: 0.1149 - loss: 0.0000e+00 - val_accuracy: 0.1138 - val_loss: 0.0000e+00\n",
      "Epoch 14/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 386us/step - accuracy: 0.1157 - loss: 0.0000e+00 - val_accuracy: 0.1138 - val_loss: 0.0000e+00\n",
      "Epoch 15/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 373us/step - accuracy: 0.1144 - loss: 0.0000e+00 - val_accuracy: 0.1138 - val_loss: 0.0000e+00\n",
      "Epoch 16/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 397us/step - accuracy: 0.1157 - loss: 0.0000e+00 - val_accuracy: 0.1138 - val_loss: 0.0000e+00\n",
      "Epoch 17/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - accuracy: 0.1143 - loss: 0.0000e+00 - val_accuracy: 0.1138 - val_loss: 0.0000e+00\n",
      "Epoch 18/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 369us/step - accuracy: 0.1155 - loss: 0.0000e+00 - val_accuracy: 0.1138 - val_loss: 0.0000e+00\n",
      "Epoch 19/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 434us/step - accuracy: 0.1157 - loss: 0.0000e+00 - val_accuracy: 0.1138 - val_loss: 0.0000e+00\n",
      "Epoch 20/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 583us/step - accuracy: 0.1145 - loss: 0.0000e+00 - val_accuracy: 0.1138 - val_loss: 0.0000e+00\n",
      "Epoch 21/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 408us/step - accuracy: 0.1163 - loss: 0.0000e+00 - val_accuracy: 0.1138 - val_loss: 0.0000e+00\n",
      "Epoch 22/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 362us/step - accuracy: 0.1146 - loss: 0.0000e+00 - val_accuracy: 0.1138 - val_loss: 0.0000e+00\n",
      "Epoch 23/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 383us/step - accuracy: 0.1151 - loss: 0.0000e+00 - val_accuracy: 0.1138 - val_loss: 0.0000e+00\n",
      "Epoch 24/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 425us/step - accuracy: 0.1176 - loss: 0.0000e+00 - val_accuracy: 0.1138 - val_loss: 0.0000e+00\n",
      "Epoch 25/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 379us/step - accuracy: 0.1140 - loss: 0.0000e+00 - val_accuracy: 0.1138 - val_loss: 0.0000e+00\n",
      "Epoch 26/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 429us/step - accuracy: 0.1149 - loss: 0.0000e+00 - val_accuracy: 0.1138 - val_loss: 0.0000e+00\n",
      "Epoch 27/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 430us/step - accuracy: 0.1143 - loss: 0.0000e+00 - val_accuracy: 0.1138 - val_loss: 0.0000e+00\n",
      "Epoch 28/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 410us/step - accuracy: 0.1167 - loss: 0.0000e+00 - val_accuracy: 0.1138 - val_loss: 0.0000e+00\n",
      "Epoch 29/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 382us/step - accuracy: 0.1161 - loss: 0.0000e+00 - val_accuracy: 0.1138 - val_loss: 0.0000e+00\n",
      "Epoch 30/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 425us/step - accuracy: 0.1161 - loss: 0.0000e+00 - val_accuracy: 0.1138 - val_loss: 0.0000e+00\n",
      "Epoch 31/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 397us/step - accuracy: 0.1168 - loss: 0.0000e+00 - val_accuracy: 0.1138 - val_loss: 0.0000e+00\n",
      "Epoch 32/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - accuracy: 0.1140 - loss: 0.0000e+00 - val_accuracy: 0.1138 - val_loss: 0.0000e+00\n",
      "Epoch 33/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 374us/step - accuracy: 0.1158 - loss: 0.0000e+00 - val_accuracy: 0.1138 - val_loss: 0.0000e+00\n",
      "Epoch 34/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - accuracy: 0.1150 - loss: 0.0000e+00 - val_accuracy: 0.1138 - val_loss: 0.0000e+00\n",
      "Epoch 35/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 430us/step - accuracy: 0.1161 - loss: 0.0000e+00 - val_accuracy: 0.1138 - val_loss: 0.0000e+00\n",
      "Epoch 36/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 367us/step - accuracy: 0.1160 - loss: 0.0000e+00 - val_accuracy: 0.1138 - val_loss: 0.0000e+00\n",
      "Epoch 37/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 343us/step - accuracy: 0.1153 - loss: 0.0000e+00 - val_accuracy: 0.1138 - val_loss: 0.0000e+00\n",
      "Epoch 38/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 456us/step - accuracy: 0.1166 - loss: 0.0000e+00 - val_accuracy: 0.1138 - val_loss: 0.0000e+00\n",
      "Epoch 39/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 357us/step - accuracy: 0.1157 - loss: 0.0000e+00 - val_accuracy: 0.1138 - val_loss: 0.0000e+00\n",
      "Epoch 40/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 374us/step - accuracy: 0.1138 - loss: 0.0000e+00 - val_accuracy: 0.1138 - val_loss: 0.0000e+00\n",
      "Epoch 41/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 408us/step - accuracy: 0.1155 - loss: 0.0000e+00 - val_accuracy: 0.1138 - val_loss: 0.0000e+00\n",
      "Epoch 42/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - accuracy: 0.1149 - loss: 0.0000e+00 - val_accuracy: 0.1138 - val_loss: 0.0000e+00\n",
      "Epoch 43/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 371us/step - accuracy: 0.1154 - loss: 0.0000e+00 - val_accuracy: 0.1138 - val_loss: 0.0000e+00\n",
      "Epoch 44/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 424us/step - accuracy: 0.1127 - loss: 0.0000e+00 - val_accuracy: 0.1138 - val_loss: 0.0000e+00\n",
      "Epoch 45/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 369us/step - accuracy: 0.1166 - loss: 0.0000e+00 - val_accuracy: 0.1138 - val_loss: 0.0000e+00\n",
      "Epoch 46/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 371us/step - accuracy: 0.1140 - loss: 0.0000e+00 - val_accuracy: 0.1138 - val_loss: 0.0000e+00\n",
      "Epoch 47/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 446us/step - accuracy: 0.1137 - loss: 0.0000e+00 - val_accuracy: 0.1138 - val_loss: 0.0000e+00\n",
      "Epoch 48/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 541us/step - accuracy: 0.1175 - loss: 0.0000e+00 - val_accuracy: 0.1138 - val_loss: 0.0000e+00\n",
      "Epoch 49/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 452us/step - accuracy: 0.1132 - loss: 0.0000e+00 - val_accuracy: 0.1138 - val_loss: 0.0000e+00\n",
      "Epoch 50/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 359us/step - accuracy: 0.1128 - loss: 0.0000e+00 - val_accuracy: 0.1138 - val_loss: 0.0000e+00\n",
      "Epoch 51/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 364us/step - accuracy: 0.1132 - loss: 0.0000e+00 - val_accuracy: 0.1138 - val_loss: 0.0000e+00\n",
      "Epoch 52/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 401us/step - accuracy: 0.1146 - loss: 0.0000e+00 - val_accuracy: 0.1138 - val_loss: 0.0000e+00\n",
      "Epoch 53/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 354us/step - accuracy: 0.1150 - loss: 0.0000e+00 - val_accuracy: 0.1138 - val_loss: 0.0000e+00\n",
      "Epoch 54/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 359us/step - accuracy: 0.1138 - loss: 0.0000e+00 - val_accuracy: 0.1138 - val_loss: 0.0000e+00\n",
      "Epoch 55/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 422us/step - accuracy: 0.1168 - loss: 0.0000e+00 - val_accuracy: 0.1138 - val_loss: 0.0000e+00\n",
      "Epoch 56/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 369us/step - accuracy: 0.1163 - loss: 0.0000e+00 - val_accuracy: 0.1138 - val_loss: 0.0000e+00\n",
      "Epoch 57/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 352us/step - accuracy: 0.1170 - loss: 0.0000e+00 - val_accuracy: 0.1138 - val_loss: 0.0000e+00\n",
      "Epoch 58/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - accuracy: 0.1149 - loss: 0.0000e+00 - val_accuracy: 0.1138 - val_loss: 0.0000e+00\n",
      "Epoch 59/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 339us/step - accuracy: 0.1162 - loss: 0.0000e+00 - val_accuracy: 0.1138 - val_loss: 0.0000e+00\n",
      "Epoch 60/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 337us/step - accuracy: 0.1165 - loss: 0.0000e+00 - val_accuracy: 0.1138 - val_loss: 0.0000e+00\n",
      "Epoch 61/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 395us/step - accuracy: 0.1151 - loss: 0.0000e+00 - val_accuracy: 0.1138 - val_loss: 0.0000e+00\n",
      "Epoch 62/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 360us/step - accuracy: 0.1143 - loss: 0.0000e+00 - val_accuracy: 0.1138 - val_loss: 0.0000e+00\n",
      "Epoch 63/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 361us/step - accuracy: 0.1143 - loss: 0.0000e+00 - val_accuracy: 0.1138 - val_loss: 0.0000e+00\n",
      "Epoch 64/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 416us/step - accuracy: 0.1134 - loss: 0.0000e+00 - val_accuracy: 0.1138 - val_loss: 0.0000e+00\n",
      "Epoch 65/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 364us/step - accuracy: 0.1155 - loss: 0.0000e+00 - val_accuracy: 0.1138 - val_loss: 0.0000e+00\n",
      "Epoch 66/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 339us/step - accuracy: 0.1163 - loss: 0.0000e+00 - val_accuracy: 0.1138 - val_loss: 0.0000e+00\n",
      "Epoch 67/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 427us/step - accuracy: 0.1146 - loss: 0.0000e+00 - val_accuracy: 0.1138 - val_loss: 0.0000e+00\n",
      "Epoch 68/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 344us/step - accuracy: 0.1161 - loss: 0.0000e+00 - val_accuracy: 0.1138 - val_loss: 0.0000e+00\n",
      "Epoch 69/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 391us/step - accuracy: 0.1170 - loss: 0.0000e+00 - val_accuracy: 0.1138 - val_loss: 0.0000e+00\n",
      "Epoch 70/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 393us/step - accuracy: 0.1153 - loss: 0.0000e+00 - val_accuracy: 0.1138 - val_loss: 0.0000e+00\n",
      "Epoch 71/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 340us/step - accuracy: 0.1151 - loss: 0.0000e+00 - val_accuracy: 0.1138 - val_loss: 0.0000e+00\n",
      "Epoch 72/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 344us/step - accuracy: 0.1150 - loss: 0.0000e+00 - val_accuracy: 0.1138 - val_loss: 0.0000e+00\n",
      "Epoch 73/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 449us/step - accuracy: 0.1156 - loss: 0.0000e+00 - val_accuracy: 0.1138 - val_loss: 0.0000e+00\n",
      "Epoch 74/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 341us/step - accuracy: 0.1145 - loss: 0.0000e+00 - val_accuracy: 0.1138 - val_loss: 0.0000e+00\n",
      "Epoch 75/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 386us/step - accuracy: 0.1128 - loss: 0.0000e+00 - val_accuracy: 0.1138 - val_loss: 0.0000e+00\n",
      "Epoch 76/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 413us/step - accuracy: 0.1156 - loss: 0.0000e+00 - val_accuracy: 0.1138 - val_loss: 0.0000e+00\n",
      "Epoch 77/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - accuracy: 0.1150 - loss: 0.0000e+00 - val_accuracy: 0.1138 - val_loss: 0.0000e+00\n",
      "Epoch 78/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 378us/step - accuracy: 0.1159 - loss: 0.0000e+00 - val_accuracy: 0.1138 - val_loss: 0.0000e+00\n",
      "Epoch 79/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 430us/step - accuracy: 0.1163 - loss: 0.0000e+00 - val_accuracy: 0.1138 - val_loss: 0.0000e+00\n",
      "Epoch 80/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 364us/step - accuracy: 0.1158 - loss: 0.0000e+00 - val_accuracy: 0.1138 - val_loss: 0.0000e+00\n",
      "Epoch 81/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 367us/step - accuracy: 0.1156 - loss: 0.0000e+00 - val_accuracy: 0.1138 - val_loss: 0.0000e+00\n",
      "Epoch 82/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 418us/step - accuracy: 0.1144 - loss: 0.0000e+00 - val_accuracy: 0.1138 - val_loss: 0.0000e+00\n",
      "Epoch 83/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 487us/step - accuracy: 0.1147 - loss: 0.0000e+00 - val_accuracy: 0.1138 - val_loss: 0.0000e+00\n",
      "Epoch 84/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 397us/step - accuracy: 0.1172 - loss: 0.0000e+00 - val_accuracy: 0.1138 - val_loss: 0.0000e+00\n",
      "Epoch 85/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - accuracy: 0.1172 - loss: 0.0000e+00 - val_accuracy: 0.1138 - val_loss: 0.0000e+00\n",
      "Epoch 86/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 358us/step - accuracy: 0.1165 - loss: 0.0000e+00 - val_accuracy: 0.1138 - val_loss: 0.0000e+00\n",
      "Epoch 87/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 397us/step - accuracy: 0.1133 - loss: 0.0000e+00 - val_accuracy: 0.1138 - val_loss: 0.0000e+00\n",
      "Epoch 88/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 353us/step - accuracy: 0.1147 - loss: 0.0000e+00 - val_accuracy: 0.1138 - val_loss: 0.0000e+00\n",
      "Epoch 89/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414us/step - accuracy: 0.1138 - loss: 0.0000e+00 - val_accuracy: 0.1138 - val_loss: 0.0000e+00\n",
      "Epoch 90/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414us/step - accuracy: 0.1145 - loss: 0.0000e+00 - val_accuracy: 0.1138 - val_loss: 0.0000e+00\n",
      "Epoch 91/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 386us/step - accuracy: 0.1150 - loss: 0.0000e+00 - val_accuracy: 0.1138 - val_loss: 0.0000e+00\n",
      "Epoch 92/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 459us/step - accuracy: 0.1146 - loss: 0.0000e+00 - val_accuracy: 0.1138 - val_loss: 0.0000e+00\n",
      "Epoch 93/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 383us/step - accuracy: 0.1156 - loss: 0.0000e+00 - val_accuracy: 0.1138 - val_loss: 0.0000e+00\n",
      "Epoch 94/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 381us/step - accuracy: 0.1159 - loss: 0.0000e+00 - val_accuracy: 0.1138 - val_loss: 0.0000e+00\n",
      "Epoch 95/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 539us/step - accuracy: 0.1144 - loss: 0.0000e+00 - val_accuracy: 0.1138 - val_loss: 0.0000e+00\n",
      "Epoch 96/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 367us/step - accuracy: 0.1166 - loss: 0.0000e+00 - val_accuracy: 0.1138 - val_loss: 0.0000e+00\n",
      "Epoch 97/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 437us/step - accuracy: 0.1151 - loss: 0.0000e+00 - val_accuracy: 0.1138 - val_loss: 0.0000e+00\n",
      "Epoch 98/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 355us/step - accuracy: 0.1153 - loss: 0.0000e+00 - val_accuracy: 0.1138 - val_loss: 0.0000e+00\n",
      "Epoch 99/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 362us/step - accuracy: 0.1163 - loss: 0.0000e+00 - val_accuracy: 0.1138 - val_loss: 0.0000e+00\n",
      "Epoch 100/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 410us/step - accuracy: 0.1137 - loss: 0.0000e+00 - val_accuracy: 0.1138 - val_loss: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x3087fcd50>"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit model\n",
    "num_epochs = 100\n",
    "\n",
    "nn_model.fit(X_train_scaled, y_train,\n",
    "          epochs=num_epochs,\n",
    "          batch_size=100,\n",
    "          validation_split=0.2,     # This 'validation_split' is telling the neural network to keep 20% of the data to validate its score on the training set... this is to help AVOID OVERFITTING. \n",
    "          shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1251/1251 - 0s - 237us/step - accuracy: 0.1130 - loss: 0.0000e+00\n",
      "Loss: 0.0, Accuracy: 0.11304435133934021\n"
     ]
    }
   ],
   "source": [
    "# Show model loss and accuracy\n",
    "\n",
    "# Evaluate the model loss and accuracy metrics using the evaluate method and the test data\n",
    "model_loss, model_accuracy = nn_model.evaluate(X_test_scaled, y_test, verbose=2)\n",
    "\n",
    "# Display the evaluation results\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1251/1251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 221us/step\n",
      "\u001b[1m3553/3553\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 229us/step\n"
     ]
    }
   ],
   "source": [
    "# Predict values using testing data\n",
    "nn_test_predictions = nn_model.predict(X_test_scaled)\n",
    "nn_train_predictions = nn_model.predict(X_train_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Evaluate the model using a classification report\n",
    "# from sklearn.metrics import classification_report\n",
    "# training_report = classification_report(nn_train_predictions, nn_test_predictions)\n",
    "# print(training_report)\n",
    "\n",
    "# # Evaluate the model's ability to predict the trading signal for the testing data using a classification report\n",
    "# training_report = classification_report(y_test, testing_signal_predictions)\n",
    "# print(training_report)\n",
    "\n",
    "# # Save model history for further manipulation\n",
    "# model_history = model.history.model_history.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now 15 minute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>close</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>trade_count</th>\n",
       "      <th>open</th>\n",
       "      <th>volume</th>\n",
       "      <th>vwap</th>\n",
       "      <th>pct_returns</th>\n",
       "      <th>SMA5</th>\n",
       "      <th>...</th>\n",
       "      <th>COPP</th>\n",
       "      <th>CMO</th>\n",
       "      <th>FISH</th>\n",
       "      <th>SQZMI</th>\n",
       "      <th>VPT</th>\n",
       "      <th>FVE</th>\n",
       "      <th>VFI</th>\n",
       "      <th>MSD</th>\n",
       "      <th>STC</th>\n",
       "      <th>signal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-01-03 15:04:00+00:00</td>\n",
       "      <td>126.5001</td>\n",
       "      <td>126.880</td>\n",
       "      <td>126.4166</td>\n",
       "      <td>5733</td>\n",
       "      <td>126.820</td>\n",
       "      <td>513722</td>\n",
       "      <td>126.624892</td>\n",
       "      <td>-0.002516</td>\n",
       "      <td>126.87386</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.878051</td>\n",
       "      <td>-65.583650</td>\n",
       "      <td>-4.458619</td>\n",
       "      <td>False</td>\n",
       "      <td>-9.952525e+06</td>\n",
       "      <td>-43.838967</td>\n",
       "      <td>-25.409400</td>\n",
       "      <td>1.034633</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-01-03 15:05:00+00:00</td>\n",
       "      <td>126.8500</td>\n",
       "      <td>126.895</td>\n",
       "      <td>126.4400</td>\n",
       "      <td>3763</td>\n",
       "      <td>126.505</td>\n",
       "      <td>362900</td>\n",
       "      <td>126.625878</td>\n",
       "      <td>0.002766</td>\n",
       "      <td>126.80786</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.719298</td>\n",
       "      <td>-40.134546</td>\n",
       "      <td>-4.465828</td>\n",
       "      <td>False</td>\n",
       "      <td>-9.402193e+06</td>\n",
       "      <td>-43.321203</td>\n",
       "      <td>-24.707011</td>\n",
       "      <td>0.967187</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-01-03 15:06:00+00:00</td>\n",
       "      <td>126.5800</td>\n",
       "      <td>126.870</td>\n",
       "      <td>126.5300</td>\n",
       "      <td>2930</td>\n",
       "      <td>126.860</td>\n",
       "      <td>240388</td>\n",
       "      <td>126.664497</td>\n",
       "      <td>-0.002128</td>\n",
       "      <td>126.71786</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.551580</td>\n",
       "      <td>-47.104800</td>\n",
       "      <td>-4.057573</td>\n",
       "      <td>False</td>\n",
       "      <td>-9.798127e+06</td>\n",
       "      <td>-39.135081</td>\n",
       "      <td>-24.923630</td>\n",
       "      <td>0.907692</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-01-03 15:07:00+00:00</td>\n",
       "      <td>126.7100</td>\n",
       "      <td>126.870</td>\n",
       "      <td>126.5000</td>\n",
       "      <td>3189</td>\n",
       "      <td>126.580</td>\n",
       "      <td>289721</td>\n",
       "      <td>126.666956</td>\n",
       "      <td>0.001027</td>\n",
       "      <td>126.69186</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.402012</td>\n",
       "      <td>-38.479113</td>\n",
       "      <td>-3.693347</td>\n",
       "      <td>False</td>\n",
       "      <td>-9.594539e+06</td>\n",
       "      <td>-32.305140</td>\n",
       "      <td>-24.862300</td>\n",
       "      <td>0.792548</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-01-03 15:08:00+00:00</td>\n",
       "      <td>126.7066</td>\n",
       "      <td>126.760</td>\n",
       "      <td>126.5601</td>\n",
       "      <td>2861</td>\n",
       "      <td>126.705</td>\n",
       "      <td>255144</td>\n",
       "      <td>126.687038</td>\n",
       "      <td>-0.000027</td>\n",
       "      <td>126.66934</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.241145</td>\n",
       "      <td>-38.583764</td>\n",
       "      <td>-3.567436</td>\n",
       "      <td>False</td>\n",
       "      <td>-9.590454e+06</td>\n",
       "      <td>-32.682043</td>\n",
       "      <td>-24.646221</td>\n",
       "      <td>0.705603</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 99 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   timestamp     close     high       low  trade_count  \\\n",
       "0  2023-01-03 15:04:00+00:00  126.5001  126.880  126.4166         5733   \n",
       "1  2023-01-03 15:05:00+00:00  126.8500  126.895  126.4400         3763   \n",
       "2  2023-01-03 15:06:00+00:00  126.5800  126.870  126.5300         2930   \n",
       "3  2023-01-03 15:07:00+00:00  126.7100  126.870  126.5000         3189   \n",
       "4  2023-01-03 15:08:00+00:00  126.7066  126.760  126.5601         2861   \n",
       "\n",
       "      open  volume        vwap  pct_returns       SMA5  ...      COPP  \\\n",
       "0  126.820  513722  126.624892    -0.002516  126.87386  ... -2.878051   \n",
       "1  126.505  362900  126.625878     0.002766  126.80786  ... -2.719298   \n",
       "2  126.860  240388  126.664497    -0.002128  126.71786  ... -2.551580   \n",
       "3  126.580  289721  126.666956     0.001027  126.69186  ... -2.402012   \n",
       "4  126.705  255144  126.687038    -0.000027  126.66934  ... -2.241145   \n",
       "\n",
       "         CMO      FISH  SQZMI           VPT        FVE        VFI       MSD  \\\n",
       "0 -65.583650 -4.458619  False -9.952525e+06 -43.838967 -25.409400  1.034633   \n",
       "1 -40.134546 -4.465828  False -9.402193e+06 -43.321203 -24.707011  0.967187   \n",
       "2 -47.104800 -4.057573  False -9.798127e+06 -39.135081 -24.923630  0.907692   \n",
       "3 -38.479113 -3.693347  False -9.594539e+06 -32.305140 -24.862300  0.792548   \n",
       "4 -38.583764 -3.567436  False -9.590454e+06 -32.682043 -24.646221  0.705603   \n",
       "\n",
       "   STC  signal  \n",
       "0  0.0       0  \n",
       "1  0.0       0  \n",
       "2  0.0       0  \n",
       "3  0.0       0  \n",
       "4  0.0       0  \n",
       "\n",
       "[5 rows x 99 columns]"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import indicator dataframe\n",
    "df = pd.read_csv(\"../algotrader2/resources/aapl_1min_pivot_point_indicator_df.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>close</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>trade_count</th>\n",
       "      <th>open</th>\n",
       "      <th>volume</th>\n",
       "      <th>vwap</th>\n",
       "      <th>pct_returns</th>\n",
       "      <th>SMA5</th>\n",
       "      <th>...</th>\n",
       "      <th>COPP</th>\n",
       "      <th>CMO</th>\n",
       "      <th>FISH</th>\n",
       "      <th>SQZMI</th>\n",
       "      <th>VPT</th>\n",
       "      <th>FVE</th>\n",
       "      <th>VFI</th>\n",
       "      <th>MSD</th>\n",
       "      <th>STC</th>\n",
       "      <th>signal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-01-03 15:04:00+00:00</td>\n",
       "      <td>126.5001</td>\n",
       "      <td>126.8800</td>\n",
       "      <td>126.4166</td>\n",
       "      <td>5733</td>\n",
       "      <td>126.8200</td>\n",
       "      <td>513722</td>\n",
       "      <td>126.624892</td>\n",
       "      <td>-0.002516</td>\n",
       "      <td>126.87386</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.878051</td>\n",
       "      <td>-65.583650</td>\n",
       "      <td>-4.458619</td>\n",
       "      <td>False</td>\n",
       "      <td>-9.952525e+06</td>\n",
       "      <td>-43.838967</td>\n",
       "      <td>-25.409400</td>\n",
       "      <td>1.034633</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-01-03 15:05:00+00:00</td>\n",
       "      <td>126.8500</td>\n",
       "      <td>126.8950</td>\n",
       "      <td>126.4400</td>\n",
       "      <td>3763</td>\n",
       "      <td>126.5050</td>\n",
       "      <td>362900</td>\n",
       "      <td>126.625878</td>\n",
       "      <td>0.002766</td>\n",
       "      <td>126.80786</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.719298</td>\n",
       "      <td>-40.134546</td>\n",
       "      <td>-4.465828</td>\n",
       "      <td>False</td>\n",
       "      <td>-9.402193e+06</td>\n",
       "      <td>-43.321203</td>\n",
       "      <td>-24.707011</td>\n",
       "      <td>0.967187</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-01-03 15:06:00+00:00</td>\n",
       "      <td>126.5800</td>\n",
       "      <td>126.8700</td>\n",
       "      <td>126.5300</td>\n",
       "      <td>2930</td>\n",
       "      <td>126.8600</td>\n",
       "      <td>240388</td>\n",
       "      <td>126.664497</td>\n",
       "      <td>-0.002128</td>\n",
       "      <td>126.71786</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.551580</td>\n",
       "      <td>-47.104800</td>\n",
       "      <td>-4.057573</td>\n",
       "      <td>False</td>\n",
       "      <td>-9.798127e+06</td>\n",
       "      <td>-39.135081</td>\n",
       "      <td>-24.923630</td>\n",
       "      <td>0.907692</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-01-03 15:07:00+00:00</td>\n",
       "      <td>126.7100</td>\n",
       "      <td>126.8700</td>\n",
       "      <td>126.5000</td>\n",
       "      <td>3189</td>\n",
       "      <td>126.5800</td>\n",
       "      <td>289721</td>\n",
       "      <td>126.666956</td>\n",
       "      <td>0.001027</td>\n",
       "      <td>126.69186</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.402012</td>\n",
       "      <td>-38.479113</td>\n",
       "      <td>-3.693347</td>\n",
       "      <td>False</td>\n",
       "      <td>-9.594539e+06</td>\n",
       "      <td>-32.305140</td>\n",
       "      <td>-24.862300</td>\n",
       "      <td>0.792548</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-01-03 15:08:00+00:00</td>\n",
       "      <td>126.7066</td>\n",
       "      <td>126.7600</td>\n",
       "      <td>126.5601</td>\n",
       "      <td>2861</td>\n",
       "      <td>126.7050</td>\n",
       "      <td>255144</td>\n",
       "      <td>126.687038</td>\n",
       "      <td>-0.000027</td>\n",
       "      <td>126.66934</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.241145</td>\n",
       "      <td>-38.583764</td>\n",
       "      <td>-3.567436</td>\n",
       "      <td>False</td>\n",
       "      <td>-9.590454e+06</td>\n",
       "      <td>-32.682043</td>\n",
       "      <td>-24.646221</td>\n",
       "      <td>0.705603</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>2023-01-03 16:40:00+00:00</td>\n",
       "      <td>125.3050</td>\n",
       "      <td>125.3500</td>\n",
       "      <td>125.2400</td>\n",
       "      <td>1750</td>\n",
       "      <td>125.2501</td>\n",
       "      <td>154973</td>\n",
       "      <td>125.287739</td>\n",
       "      <td>0.000599</td>\n",
       "      <td>125.16050</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.051447</td>\n",
       "      <td>22.539067</td>\n",
       "      <td>0.583741</td>\n",
       "      <td>False</td>\n",
       "      <td>-1.526288e+07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-28.352511</td>\n",
       "      <td>0.127903</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>2023-01-03 16:41:00+00:00</td>\n",
       "      <td>125.2100</td>\n",
       "      <td>125.3300</td>\n",
       "      <td>125.1544</td>\n",
       "      <td>1433</td>\n",
       "      <td>125.3050</td>\n",
       "      <td>134421</td>\n",
       "      <td>125.236639</td>\n",
       "      <td>-0.000758</td>\n",
       "      <td>125.20100</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.020410</td>\n",
       "      <td>9.325659</td>\n",
       "      <td>0.956244</td>\n",
       "      <td>False</td>\n",
       "      <td>-1.540833e+07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-29.006483</td>\n",
       "      <td>0.122093</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>2023-01-03 16:42:00+00:00</td>\n",
       "      <td>125.0856</td>\n",
       "      <td>125.2117</td>\n",
       "      <td>125.0600</td>\n",
       "      <td>1606</td>\n",
       "      <td>125.2100</td>\n",
       "      <td>218451</td>\n",
       "      <td>125.152599</td>\n",
       "      <td>-0.000994</td>\n",
       "      <td>125.20012</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003404</td>\n",
       "      <td>-5.500364</td>\n",
       "      <td>0.876530</td>\n",
       "      <td>False</td>\n",
       "      <td>-1.576661e+07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-29.661408</td>\n",
       "      <td>0.120787</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>2023-01-03 16:43:00+00:00</td>\n",
       "      <td>125.0596</td>\n",
       "      <td>125.1399</td>\n",
       "      <td>125.0400</td>\n",
       "      <td>1251</td>\n",
       "      <td>125.0818</td>\n",
       "      <td>117044</td>\n",
       "      <td>125.074116</td>\n",
       "      <td>-0.000208</td>\n",
       "      <td>125.17804</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.034059</td>\n",
       "      <td>-8.385571</td>\n",
       "      <td>0.584045</td>\n",
       "      <td>False</td>\n",
       "      <td>-1.581863e+07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-30.377050</td>\n",
       "      <td>0.121322</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>2023-01-03 16:44:00+00:00</td>\n",
       "      <td>124.9660</td>\n",
       "      <td>125.0650</td>\n",
       "      <td>124.9600</td>\n",
       "      <td>2381</td>\n",
       "      <td>125.0552</td>\n",
       "      <td>256887</td>\n",
       "      <td>125.008160</td>\n",
       "      <td>-0.000748</td>\n",
       "      <td>125.12524</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.052406</td>\n",
       "      <td>-18.356351</td>\n",
       "      <td>0.112427</td>\n",
       "      <td>False</td>\n",
       "      <td>-1.625509e+07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-31.417307</td>\n",
       "      <td>0.117810</td>\n",
       "      <td>99.716619</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 99 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    timestamp     close      high       low  trade_count  \\\n",
       "0   2023-01-03 15:04:00+00:00  126.5001  126.8800  126.4166         5733   \n",
       "1   2023-01-03 15:05:00+00:00  126.8500  126.8950  126.4400         3763   \n",
       "2   2023-01-03 15:06:00+00:00  126.5800  126.8700  126.5300         2930   \n",
       "3   2023-01-03 15:07:00+00:00  126.7100  126.8700  126.5000         3189   \n",
       "4   2023-01-03 15:08:00+00:00  126.7066  126.7600  126.5601         2861   \n",
       "..                        ...       ...       ...       ...          ...   \n",
       "95  2023-01-03 16:40:00+00:00  125.3050  125.3500  125.2400         1750   \n",
       "96  2023-01-03 16:41:00+00:00  125.2100  125.3300  125.1544         1433   \n",
       "97  2023-01-03 16:42:00+00:00  125.0856  125.2117  125.0600         1606   \n",
       "98  2023-01-03 16:43:00+00:00  125.0596  125.1399  125.0400         1251   \n",
       "99  2023-01-03 16:44:00+00:00  124.9660  125.0650  124.9600         2381   \n",
       "\n",
       "        open  volume        vwap  pct_returns       SMA5  ...      COPP  \\\n",
       "0   126.8200  513722  126.624892    -0.002516  126.87386  ... -2.878051   \n",
       "1   126.5050  362900  126.625878     0.002766  126.80786  ... -2.719298   \n",
       "2   126.8600  240388  126.664497    -0.002128  126.71786  ... -2.551580   \n",
       "3   126.5800  289721  126.666956     0.001027  126.69186  ... -2.402012   \n",
       "4   126.7050  255144  126.687038    -0.000027  126.66934  ... -2.241145   \n",
       "..       ...     ...         ...          ...        ...  ...       ...   \n",
       "95  125.2501  154973  125.287739     0.000599  125.16050  ... -0.051447   \n",
       "96  125.3050  134421  125.236639    -0.000758  125.20100  ... -0.020410   \n",
       "97  125.2100  218451  125.152599    -0.000994  125.20012  ... -0.003404   \n",
       "98  125.0818  117044  125.074116    -0.000208  125.17804  ... -0.034059   \n",
       "99  125.0552  256887  125.008160    -0.000748  125.12524  ... -0.052406   \n",
       "\n",
       "          CMO      FISH  SQZMI           VPT        FVE        VFI       MSD  \\\n",
       "0  -65.583650 -4.458619  False -9.952525e+06 -43.838967 -25.409400  1.034633   \n",
       "1  -40.134546 -4.465828  False -9.402193e+06 -43.321203 -24.707011  0.967187   \n",
       "2  -47.104800 -4.057573  False -9.798127e+06 -39.135081 -24.923630  0.907692   \n",
       "3  -38.479113 -3.693347  False -9.594539e+06 -32.305140 -24.862300  0.792548   \n",
       "4  -38.583764 -3.567436  False -9.590454e+06 -32.682043 -24.646221  0.705603   \n",
       "..        ...       ...    ...           ...        ...        ...       ...   \n",
       "95  22.539067  0.583741  False -1.526288e+07   0.000000 -28.352511  0.127903   \n",
       "96   9.325659  0.956244  False -1.540833e+07   0.000000 -29.006483  0.122093   \n",
       "97  -5.500364  0.876530  False -1.576661e+07   0.000000 -29.661408  0.120787   \n",
       "98  -8.385571  0.584045  False -1.581863e+07   0.000000 -30.377050  0.121322   \n",
       "99 -18.356351  0.112427  False -1.625509e+07   0.000000 -31.417307  0.117810   \n",
       "\n",
       "           STC  signal  \n",
       "0     0.000000       0  \n",
       "1     0.000000       0  \n",
       "2     0.000000       0  \n",
       "3     0.000000       0  \n",
       "4     0.000000       0  \n",
       "..         ...     ...  \n",
       "95  100.000000       1  \n",
       "96  100.000000       0  \n",
       "97  100.000000       0  \n",
       "98  100.000000       0  \n",
       "99   99.716619       0  \n",
       "\n",
       "[100 rows x 99 columns]"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>close</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>trade_count</th>\n",
       "      <th>open</th>\n",
       "      <th>volume</th>\n",
       "      <th>vwap</th>\n",
       "      <th>pct_returns</th>\n",
       "      <th>SMA5</th>\n",
       "      <th>SMA10</th>\n",
       "      <th>...</th>\n",
       "      <th>CCI</th>\n",
       "      <th>COPP</th>\n",
       "      <th>CMO</th>\n",
       "      <th>FISH</th>\n",
       "      <th>SQZMI</th>\n",
       "      <th>VPT</th>\n",
       "      <th>FVE</th>\n",
       "      <th>VFI</th>\n",
       "      <th>MSD</th>\n",
       "      <th>STC</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-01-03 15:05:00+00:00</th>\n",
       "      <td>126.5001</td>\n",
       "      <td>126.880</td>\n",
       "      <td>126.4166</td>\n",
       "      <td>5733.0</td>\n",
       "      <td>126.820</td>\n",
       "      <td>513722.0</td>\n",
       "      <td>126.624892</td>\n",
       "      <td>-0.002516</td>\n",
       "      <td>126.87386</td>\n",
       "      <td>127.15340</td>\n",
       "      <td>...</td>\n",
       "      <td>-116.423590</td>\n",
       "      <td>-2.878051</td>\n",
       "      <td>-65.583650</td>\n",
       "      <td>-4.458619</td>\n",
       "      <td>False</td>\n",
       "      <td>-9.952525e+06</td>\n",
       "      <td>-43.838967</td>\n",
       "      <td>-25.409400</td>\n",
       "      <td>1.034633</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-03 15:06:00+00:00</th>\n",
       "      <td>126.8500</td>\n",
       "      <td>126.895</td>\n",
       "      <td>126.4400</td>\n",
       "      <td>3763.0</td>\n",
       "      <td>126.505</td>\n",
       "      <td>362900.0</td>\n",
       "      <td>126.625878</td>\n",
       "      <td>0.002766</td>\n",
       "      <td>126.80786</td>\n",
       "      <td>127.06139</td>\n",
       "      <td>...</td>\n",
       "      <td>-101.126762</td>\n",
       "      <td>-2.719298</td>\n",
       "      <td>-40.134546</td>\n",
       "      <td>-4.465828</td>\n",
       "      <td>False</td>\n",
       "      <td>-9.402193e+06</td>\n",
       "      <td>-43.321203</td>\n",
       "      <td>-24.707011</td>\n",
       "      <td>0.967187</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-03 15:07:00+00:00</th>\n",
       "      <td>126.5800</td>\n",
       "      <td>126.870</td>\n",
       "      <td>126.5300</td>\n",
       "      <td>2930.0</td>\n",
       "      <td>126.860</td>\n",
       "      <td>240388.0</td>\n",
       "      <td>126.664497</td>\n",
       "      <td>-0.002128</td>\n",
       "      <td>126.71786</td>\n",
       "      <td>126.94739</td>\n",
       "      <td>...</td>\n",
       "      <td>-99.309857</td>\n",
       "      <td>-2.551580</td>\n",
       "      <td>-47.104800</td>\n",
       "      <td>-4.057573</td>\n",
       "      <td>False</td>\n",
       "      <td>-9.798127e+06</td>\n",
       "      <td>-39.135081</td>\n",
       "      <td>-24.923630</td>\n",
       "      <td>0.907692</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-03 15:08:00+00:00</th>\n",
       "      <td>126.7100</td>\n",
       "      <td>126.870</td>\n",
       "      <td>126.5000</td>\n",
       "      <td>3189.0</td>\n",
       "      <td>126.580</td>\n",
       "      <td>289721.0</td>\n",
       "      <td>126.666956</td>\n",
       "      <td>0.001027</td>\n",
       "      <td>126.69186</td>\n",
       "      <td>126.87129</td>\n",
       "      <td>...</td>\n",
       "      <td>-88.964539</td>\n",
       "      <td>-2.402012</td>\n",
       "      <td>-38.479113</td>\n",
       "      <td>-3.693347</td>\n",
       "      <td>False</td>\n",
       "      <td>-9.594539e+06</td>\n",
       "      <td>-32.305140</td>\n",
       "      <td>-24.862300</td>\n",
       "      <td>0.792548</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-03 15:09:00+00:00</th>\n",
       "      <td>126.7066</td>\n",
       "      <td>126.760</td>\n",
       "      <td>126.5601</td>\n",
       "      <td>2861.0</td>\n",
       "      <td>126.705</td>\n",
       "      <td>255144.0</td>\n",
       "      <td>126.687038</td>\n",
       "      <td>-0.000027</td>\n",
       "      <td>126.66934</td>\n",
       "      <td>126.81495</td>\n",
       "      <td>...</td>\n",
       "      <td>-84.000283</td>\n",
       "      <td>-2.241145</td>\n",
       "      <td>-38.583764</td>\n",
       "      <td>-3.567436</td>\n",
       "      <td>False</td>\n",
       "      <td>-9.590454e+06</td>\n",
       "      <td>-32.682043</td>\n",
       "      <td>-24.646221</td>\n",
       "      <td>0.705603</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 97 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              close     high       low  trade_count     open  \\\n",
       "timestamp                                                                      \n",
       "2023-01-03 15:05:00+00:00  126.5001  126.880  126.4166       5733.0  126.820   \n",
       "2023-01-03 15:06:00+00:00  126.8500  126.895  126.4400       3763.0  126.505   \n",
       "2023-01-03 15:07:00+00:00  126.5800  126.870  126.5300       2930.0  126.860   \n",
       "2023-01-03 15:08:00+00:00  126.7100  126.870  126.5000       3189.0  126.580   \n",
       "2023-01-03 15:09:00+00:00  126.7066  126.760  126.5601       2861.0  126.705   \n",
       "\n",
       "                             volume        vwap  pct_returns       SMA5  \\\n",
       "timestamp                                                                 \n",
       "2023-01-03 15:05:00+00:00  513722.0  126.624892    -0.002516  126.87386   \n",
       "2023-01-03 15:06:00+00:00  362900.0  126.625878     0.002766  126.80786   \n",
       "2023-01-03 15:07:00+00:00  240388.0  126.664497    -0.002128  126.71786   \n",
       "2023-01-03 15:08:00+00:00  289721.0  126.666956     0.001027  126.69186   \n",
       "2023-01-03 15:09:00+00:00  255144.0  126.687038    -0.000027  126.66934   \n",
       "\n",
       "                               SMA10  ...         CCI      COPP        CMO  \\\n",
       "timestamp                             ...                                    \n",
       "2023-01-03 15:05:00+00:00  127.15340  ... -116.423590 -2.878051 -65.583650   \n",
       "2023-01-03 15:06:00+00:00  127.06139  ... -101.126762 -2.719298 -40.134546   \n",
       "2023-01-03 15:07:00+00:00  126.94739  ...  -99.309857 -2.551580 -47.104800   \n",
       "2023-01-03 15:08:00+00:00  126.87129  ...  -88.964539 -2.402012 -38.479113   \n",
       "2023-01-03 15:09:00+00:00  126.81495  ...  -84.000283 -2.241145 -38.583764   \n",
       "\n",
       "                               FISH  SQZMI           VPT        FVE  \\\n",
       "timestamp                                                             \n",
       "2023-01-03 15:05:00+00:00 -4.458619  False -9.952525e+06 -43.838967   \n",
       "2023-01-03 15:06:00+00:00 -4.465828  False -9.402193e+06 -43.321203   \n",
       "2023-01-03 15:07:00+00:00 -4.057573  False -9.798127e+06 -39.135081   \n",
       "2023-01-03 15:08:00+00:00 -3.693347  False -9.594539e+06 -32.305140   \n",
       "2023-01-03 15:09:00+00:00 -3.567436  False -9.590454e+06 -32.682043   \n",
       "\n",
       "                                 VFI       MSD  STC  \n",
       "timestamp                                            \n",
       "2023-01-03 15:05:00+00:00 -25.409400  1.034633  0.0  \n",
       "2023-01-03 15:06:00+00:00 -24.707011  0.967187  0.0  \n",
       "2023-01-03 15:07:00+00:00 -24.923630  0.907692  0.0  \n",
       "2023-01-03 15:08:00+00:00 -24.862300  0.792548  0.0  \n",
       "2023-01-03 15:09:00+00:00 -24.646221  0.705603  0.0  \n",
       "\n",
       "[5 rows x 97 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start date: 2023-01-03 15:05:00+00:00\n",
      "End date: 2023-10-03 15:05:00+00:00\n"
     ]
    }
   ],
   "source": [
    "# Create our timestamp column as a datetime index, then save it as our index\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "df.set_index('timestamp', inplace=True)\n",
    "# X is everything except the signal column\n",
    "X = df.drop('signal', axis=1)\n",
    "# We should use the .shift() function so that our algorithm predicts the minute before realtime\n",
    "# Drop the row with NaN values \n",
    "X = X.shift().dropna()\n",
    "display(X.head())\n",
    "y = df[(\"signal\")]\n",
    "# Set start of training period\n",
    "training_begin = X.index.min()\n",
    "print(f\"Start date: {training_begin}\")\n",
    "# Select ending period for the training data. Since we pulled a year's worth of data\n",
    "# we will train on 9 months and then test with the rest\n",
    "training_end = X.index.min() + DateOffset(months=9)\n",
    "print(f\"End date: {training_end}\")\n",
    "# Generate the X_train and y_train DataFrames\n",
    "X_train = X.loc[training_begin:training_end]\n",
    "y_train = y.loc[training_begin:training_end]\n",
    "\n",
    "# Generate the X_test and y_test DataFrames\n",
    "X_test = X.loc[training_end:]\n",
    "y_test = y.loc[training_end:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(113680, 97)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(40002, 97)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(113680, 97)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(40002, 97)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a StandardScaler instance\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Apply the scaler model to fit the X-train data\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Transform the X_train and X_test DataFrames using the X_scaler\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)\n",
    "\n",
    "display(X_train_scaled.shape)\n",
    "display(X_test_scaled.shape)\n",
    "\n",
    "# from imblearn.over_sampling import RandomOverSampler\n",
    "# Use RandomOverSampler to resample the datase using random_state=1\n",
    "ros = RandomOverSampler(random_state=1)\n",
    "X_resampled, y_resampled = ros.fit_resample(X_train_scaled, y_train)\n",
    "display(X_train_scaled.shape)\n",
    "display(X_test_scaled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/montygash/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/dense.py:73: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# NEURAL NETWORK\n",
    "num_predictors = len(X.columns)\n",
    "num_classes = 1\n",
    "nn_model = Sequential()\n",
    "# Add dense layer(s)\n",
    "nn_model.add(Dense(10, input_dim=num_predictors, activation='relu'))\n",
    "# Drop-out layer(s)\n",
    "# nn_model.add(Dropout(.2,input_shape=(10,)))\n",
    "# Add dense layer, add Regularization\n",
    "#model.add(Dense(5, activation='relu', kernel_regularized=l2(0.01), bias_regularized=l2(0.01)))\n",
    "# Add output layer\n",
    "# Number of outputs equals number of classes\n",
    "#nn_model.add(Dense(num_classes))\n",
    "nn_model.add(Dense(num_classes, activation=\"softmax\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_13\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_13\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">    Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━┩\n",
       "│ dense_27 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                │        <span style=\"color: #00af00; text-decoration-color: #00af00\">980</span> │\n",
       "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
       "│ dense_28 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span> │\n",
       "└─────────────────────────────────┴───────────────────────────┴────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━┩\n",
       "│ dense_27 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                │        \u001b[38;5;34m980\u001b[0m │\n",
       "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
       "│ dense_28 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                 │         \u001b[38;5;34m11\u001b[0m │\n",
       "└─────────────────────────────────┴───────────────────────────┴────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">991</span> (3.87 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m991\u001b[0m (3.87 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">991</span> (3.87 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m991\u001b[0m (3.87 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compile model\n",
    "nn_model.compile(loss=\"categorical_crossentropy\",\n",
    "              optimizer=\"adam\",\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Summarize model\n",
    "nn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/montygash/anaconda3/lib/python3.11/site-packages/keras/src/losses/losses.py:22: SyntaxWarning: In loss categorical_crossentropy, expected y_pred.shape to be (batch_size, num_classes) with num_classes > 1. Received: y_pred.shape=(None, 1). Consider using 'binary_crossentropy' if you only have 2 classes.\n",
      "  return self.fn(y_true, y_pred, **self._fn_kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 471us/step - accuracy: 0.7554 - loss: 0.0000e+00 - val_accuracy: 0.7478 - val_loss: 0.0000e+00\n",
      "Epoch 2/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 362us/step - accuracy: 0.7631 - loss: 0.0000e+00 - val_accuracy: 0.7551 - val_loss: 0.0000e+00\n",
      "Epoch 3/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 392us/step - accuracy: 0.7678 - loss: 0.0000e+00 - val_accuracy: 0.7640 - val_loss: 0.0000e+00\n",
      "Epoch 4/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 386us/step - accuracy: 0.7703 - loss: 0.0000e+00 - val_accuracy: 0.7685 - val_loss: 0.0000e+00\n",
      "Epoch 5/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 357us/step - accuracy: 0.7729 - loss: 0.0000e+00 - val_accuracy: 0.7716 - val_loss: 0.0000e+00\n",
      "Epoch 6/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 357us/step - accuracy: 0.7701 - loss: 0.0000e+00 - val_accuracy: 0.7734 - val_loss: 0.0000e+00\n",
      "Epoch 7/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 407us/step - accuracy: 0.7701 - loss: 0.0000e+00 - val_accuracy: 0.7740 - val_loss: 0.0000e+00\n",
      "Epoch 8/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 360us/step - accuracy: 0.7690 - loss: 0.0000e+00 - val_accuracy: 0.7760 - val_loss: 0.0000e+00\n",
      "Epoch 9/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 358us/step - accuracy: 0.7719 - loss: 0.0000e+00 - val_accuracy: 0.7763 - val_loss: 0.0000e+00\n",
      "Epoch 10/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 402us/step - accuracy: 0.7734 - loss: 0.0000e+00 - val_accuracy: 0.7763 - val_loss: 0.0000e+00\n",
      "Epoch 11/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 408us/step - accuracy: 0.7722 - loss: 0.0000e+00 - val_accuracy: 0.7765 - val_loss: 0.0000e+00\n",
      "Epoch 12/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 354us/step - accuracy: 0.7720 - loss: 0.0000e+00 - val_accuracy: 0.7765 - val_loss: 0.0000e+00\n",
      "Epoch 13/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 455us/step - accuracy: 0.7706 - loss: 0.0000e+00 - val_accuracy: 0.7765 - val_loss: 0.0000e+00\n",
      "Epoch 14/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 366us/step - accuracy: 0.7715 - loss: 0.0000e+00 - val_accuracy: 0.7766 - val_loss: 0.0000e+00\n",
      "Epoch 15/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 384us/step - accuracy: 0.7724 - loss: 0.0000e+00 - val_accuracy: 0.7764 - val_loss: 0.0000e+00\n",
      "Epoch 16/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 427us/step - accuracy: 0.7718 - loss: 0.0000e+00 - val_accuracy: 0.7765 - val_loss: 0.0000e+00\n",
      "Epoch 17/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 361us/step - accuracy: 0.7698 - loss: 0.0000e+00 - val_accuracy: 0.7766 - val_loss: 0.0000e+00\n",
      "Epoch 18/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 383us/step - accuracy: 0.7711 - loss: 0.0000e+00 - val_accuracy: 0.7765 - val_loss: 0.0000e+00\n",
      "Epoch 19/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 431us/step - accuracy: 0.7703 - loss: 0.0000e+00 - val_accuracy: 0.7765 - val_loss: 0.0000e+00\n",
      "Epoch 20/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - accuracy: 0.7698 - loss: 0.0000e+00 - val_accuracy: 0.7766 - val_loss: 0.0000e+00\n",
      "Epoch 21/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 659us/step - accuracy: 0.7691 - loss: 0.0000e+00 - val_accuracy: 0.7766 - val_loss: 0.0000e+00\n",
      "Epoch 22/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 381us/step - accuracy: 0.7739 - loss: 0.0000e+00 - val_accuracy: 0.7766 - val_loss: 0.0000e+00\n",
      "Epoch 23/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 394us/step - accuracy: 0.7697 - loss: 0.0000e+00 - val_accuracy: 0.7766 - val_loss: 0.0000e+00\n",
      "Epoch 24/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 450us/step - accuracy: 0.7724 - loss: 0.0000e+00 - val_accuracy: 0.7766 - val_loss: 0.0000e+00\n",
      "Epoch 25/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390us/step - accuracy: 0.7737 - loss: 0.0000e+00 - val_accuracy: 0.7766 - val_loss: 0.0000e+00\n",
      "Epoch 26/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 382us/step - accuracy: 0.7711 - loss: 0.0000e+00 - val_accuracy: 0.7766 - val_loss: 0.0000e+00\n",
      "Epoch 27/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 400us/step - accuracy: 0.7712 - loss: 0.0000e+00 - val_accuracy: 0.7766 - val_loss: 0.0000e+00\n",
      "Epoch 28/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 354us/step - accuracy: 0.7712 - loss: 0.0000e+00 - val_accuracy: 0.7766 - val_loss: 0.0000e+00\n",
      "Epoch 29/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 358us/step - accuracy: 0.7717 - loss: 0.0000e+00 - val_accuracy: 0.7766 - val_loss: 0.0000e+00\n",
      "Epoch 30/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 391us/step - accuracy: 0.7708 - loss: 0.0000e+00 - val_accuracy: 0.7766 - val_loss: 0.0000e+00\n",
      "Epoch 31/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 344us/step - accuracy: 0.7706 - loss: 0.0000e+00 - val_accuracy: 0.7766 - val_loss: 0.0000e+00\n",
      "Epoch 32/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 360us/step - accuracy: 0.7704 - loss: 0.0000e+00 - val_accuracy: 0.7766 - val_loss: 0.0000e+00\n",
      "Epoch 33/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 406us/step - accuracy: 0.7709 - loss: 0.0000e+00 - val_accuracy: 0.7766 - val_loss: 0.0000e+00\n",
      "Epoch 34/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 345us/step - accuracy: 0.7725 - loss: 0.0000e+00 - val_accuracy: 0.7766 - val_loss: 0.0000e+00\n",
      "Epoch 35/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 384us/step - accuracy: 0.7718 - loss: 0.0000e+00 - val_accuracy: 0.7766 - val_loss: 0.0000e+00\n",
      "Epoch 36/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 397us/step - accuracy: 0.7723 - loss: 0.0000e+00 - val_accuracy: 0.7767 - val_loss: 0.0000e+00\n",
      "Epoch 37/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 362us/step - accuracy: 0.7707 - loss: 0.0000e+00 - val_accuracy: 0.7767 - val_loss: 0.0000e+00\n",
      "Epoch 38/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 351us/step - accuracy: 0.7707 - loss: 0.0000e+00 - val_accuracy: 0.7767 - val_loss: 0.0000e+00\n",
      "Epoch 39/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390us/step - accuracy: 0.7704 - loss: 0.0000e+00 - val_accuracy: 0.7767 - val_loss: 0.0000e+00\n",
      "Epoch 40/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 343us/step - accuracy: 0.7716 - loss: 0.0000e+00 - val_accuracy: 0.7767 - val_loss: 0.0000e+00\n",
      "Epoch 41/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 344us/step - accuracy: 0.7712 - loss: 0.0000e+00 - val_accuracy: 0.7767 - val_loss: 0.0000e+00\n",
      "Epoch 42/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - accuracy: 0.7698 - loss: 0.0000e+00 - val_accuracy: 0.7767 - val_loss: 0.0000e+00\n",
      "Epoch 43/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 372us/step - accuracy: 0.7708 - loss: 0.0000e+00 - val_accuracy: 0.7767 - val_loss: 0.0000e+00\n",
      "Epoch 44/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 409us/step - accuracy: 0.7713 - loss: 0.0000e+00 - val_accuracy: 0.7767 - val_loss: 0.0000e+00\n",
      "Epoch 45/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 436us/step - accuracy: 0.7695 - loss: 0.0000e+00 - val_accuracy: 0.7767 - val_loss: 0.0000e+00\n",
      "Epoch 46/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390us/step - accuracy: 0.7697 - loss: 0.0000e+00 - val_accuracy: 0.7767 - val_loss: 0.0000e+00\n",
      "Epoch 47/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 392us/step - accuracy: 0.7720 - loss: 0.0000e+00 - val_accuracy: 0.7767 - val_loss: 0.0000e+00\n",
      "Epoch 48/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 649us/step - accuracy: 0.7708 - loss: 0.0000e+00 - val_accuracy: 0.7767 - val_loss: 0.0000e+00\n",
      "Epoch 49/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 416us/step - accuracy: 0.7708 - loss: 0.0000e+00 - val_accuracy: 0.7767 - val_loss: 0.0000e+00\n",
      "Epoch 50/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 450us/step - accuracy: 0.7714 - loss: 0.0000e+00 - val_accuracy: 0.7767 - val_loss: 0.0000e+00\n",
      "Epoch 51/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 397us/step - accuracy: 0.7718 - loss: 0.0000e+00 - val_accuracy: 0.7767 - val_loss: 0.0000e+00\n",
      "Epoch 52/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 375us/step - accuracy: 0.7721 - loss: 0.0000e+00 - val_accuracy: 0.7767 - val_loss: 0.0000e+00\n",
      "Epoch 53/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 429us/step - accuracy: 0.7686 - loss: 0.0000e+00 - val_accuracy: 0.7767 - val_loss: 0.0000e+00\n",
      "Epoch 54/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 368us/step - accuracy: 0.7718 - loss: 0.0000e+00 - val_accuracy: 0.7766 - val_loss: 0.0000e+00\n",
      "Epoch 55/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 366us/step - accuracy: 0.7716 - loss: 0.0000e+00 - val_accuracy: 0.7766 - val_loss: 0.0000e+00\n",
      "Epoch 56/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 436us/step - accuracy: 0.7686 - loss: 0.0000e+00 - val_accuracy: 0.7766 - val_loss: 0.0000e+00\n",
      "Epoch 57/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 371us/step - accuracy: 0.7728 - loss: 0.0000e+00 - val_accuracy: 0.7766 - val_loss: 0.0000e+00\n",
      "Epoch 58/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 369us/step - accuracy: 0.7713 - loss: 0.0000e+00 - val_accuracy: 0.7766 - val_loss: 0.0000e+00\n",
      "Epoch 59/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 422us/step - accuracy: 0.7703 - loss: 0.0000e+00 - val_accuracy: 0.7767 - val_loss: 0.0000e+00\n",
      "Epoch 60/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 364us/step - accuracy: 0.7713 - loss: 0.0000e+00 - val_accuracy: 0.7767 - val_loss: 0.0000e+00\n",
      "Epoch 61/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 361us/step - accuracy: 0.7709 - loss: 0.0000e+00 - val_accuracy: 0.7767 - val_loss: 0.0000e+00\n",
      "Epoch 62/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 407us/step - accuracy: 0.7722 - loss: 0.0000e+00 - val_accuracy: 0.7767 - val_loss: 0.0000e+00\n",
      "Epoch 63/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 371us/step - accuracy: 0.7676 - loss: 0.0000e+00 - val_accuracy: 0.7767 - val_loss: 0.0000e+00\n",
      "Epoch 64/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 454us/step - accuracy: 0.7719 - loss: 0.0000e+00 - val_accuracy: 0.7767 - val_loss: 0.0000e+00\n",
      "Epoch 65/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 358us/step - accuracy: 0.7728 - loss: 0.0000e+00 - val_accuracy: 0.7767 - val_loss: 0.0000e+00\n",
      "Epoch 66/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 357us/step - accuracy: 0.7705 - loss: 0.0000e+00 - val_accuracy: 0.7767 - val_loss: 0.0000e+00\n",
      "Epoch 67/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 559us/step - accuracy: 0.7728 - loss: 0.0000e+00 - val_accuracy: 0.7767 - val_loss: 0.0000e+00\n",
      "Epoch 68/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 358us/step - accuracy: 0.7716 - loss: 0.0000e+00 - val_accuracy: 0.7767 - val_loss: 0.0000e+00\n",
      "Epoch 69/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 358us/step - accuracy: 0.7713 - loss: 0.0000e+00 - val_accuracy: 0.7767 - val_loss: 0.0000e+00\n",
      "Epoch 70/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 402us/step - accuracy: 0.7707 - loss: 0.0000e+00 - val_accuracy: 0.7767 - val_loss: 0.0000e+00\n",
      "Epoch 71/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 360us/step - accuracy: 0.7693 - loss: 0.0000e+00 - val_accuracy: 0.7767 - val_loss: 0.0000e+00\n",
      "Epoch 72/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 384us/step - accuracy: 0.7708 - loss: 0.0000e+00 - val_accuracy: 0.7767 - val_loss: 0.0000e+00\n",
      "Epoch 73/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 433us/step - accuracy: 0.7723 - loss: 0.0000e+00 - val_accuracy: 0.7767 - val_loss: 0.0000e+00\n",
      "Epoch 74/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 343us/step - accuracy: 0.7722 - loss: 0.0000e+00 - val_accuracy: 0.7767 - val_loss: 0.0000e+00\n",
      "Epoch 75/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 354us/step - accuracy: 0.7729 - loss: 0.0000e+00 - val_accuracy: 0.7767 - val_loss: 0.0000e+00\n",
      "Epoch 76/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 343us/step - accuracy: 0.7684 - loss: 0.0000e+00 - val_accuracy: 0.7767 - val_loss: 0.0000e+00\n",
      "Epoch 77/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - accuracy: 0.7706 - loss: 0.0000e+00 - val_accuracy: 0.7767 - val_loss: 0.0000e+00\n",
      "Epoch 78/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 355us/step - accuracy: 0.7690 - loss: 0.0000e+00 - val_accuracy: 0.7767 - val_loss: 0.0000e+00\n",
      "Epoch 79/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 346us/step - accuracy: 0.7725 - loss: 0.0000e+00 - val_accuracy: 0.7767 - val_loss: 0.0000e+00\n",
      "Epoch 80/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 375us/step - accuracy: 0.7727 - loss: 0.0000e+00 - val_accuracy: 0.7767 - val_loss: 0.0000e+00\n",
      "Epoch 81/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 342us/step - accuracy: 0.7689 - loss: 0.0000e+00 - val_accuracy: 0.7767 - val_loss: 0.0000e+00\n",
      "Epoch 82/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 365us/step - accuracy: 0.7711 - loss: 0.0000e+00 - val_accuracy: 0.7767 - val_loss: 0.0000e+00\n",
      "Epoch 83/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 430us/step - accuracy: 0.7732 - loss: 0.0000e+00 - val_accuracy: 0.7767 - val_loss: 0.0000e+00\n",
      "Epoch 84/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 369us/step - accuracy: 0.7693 - loss: 0.0000e+00 - val_accuracy: 0.7767 - val_loss: 0.0000e+00\n",
      "Epoch 85/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 625us/step - accuracy: 0.7720 - loss: 0.0000e+00 - val_accuracy: 0.7767 - val_loss: 0.0000e+00\n",
      "Epoch 86/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 363us/step - accuracy: 0.7703 - loss: 0.0000e+00 - val_accuracy: 0.7767 - val_loss: 0.0000e+00\n",
      "Epoch 87/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 343us/step - accuracy: 0.7707 - loss: 0.0000e+00 - val_accuracy: 0.7767 - val_loss: 0.0000e+00\n",
      "Epoch 88/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390us/step - accuracy: 0.7696 - loss: 0.0000e+00 - val_accuracy: 0.7767 - val_loss: 0.0000e+00\n",
      "Epoch 89/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 343us/step - accuracy: 0.7710 - loss: 0.0000e+00 - val_accuracy: 0.7767 - val_loss: 0.0000e+00\n",
      "Epoch 90/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 345us/step - accuracy: 0.7704 - loss: 0.0000e+00 - val_accuracy: 0.7767 - val_loss: 0.0000e+00\n",
      "Epoch 91/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - accuracy: 0.7690 - loss: 0.0000e+00 - val_accuracy: 0.7767 - val_loss: 0.0000e+00\n",
      "Epoch 92/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 345us/step - accuracy: 0.7701 - loss: 0.0000e+00 - val_accuracy: 0.7767 - val_loss: 0.0000e+00\n",
      "Epoch 93/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 350us/step - accuracy: 0.7712 - loss: 0.0000e+00 - val_accuracy: 0.7767 - val_loss: 0.0000e+00\n",
      "Epoch 94/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 391us/step - accuracy: 0.7695 - loss: 0.0000e+00 - val_accuracy: 0.7767 - val_loss: 0.0000e+00\n",
      "Epoch 95/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 344us/step - accuracy: 0.7704 - loss: 0.0000e+00 - val_accuracy: 0.7767 - val_loss: 0.0000e+00\n",
      "Epoch 96/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 345us/step - accuracy: 0.7706 - loss: 0.0000e+00 - val_accuracy: 0.7767 - val_loss: 0.0000e+00\n",
      "Epoch 97/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387us/step - accuracy: 0.7694 - loss: 0.0000e+00 - val_accuracy: 0.7767 - val_loss: 0.0000e+00\n",
      "Epoch 98/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 344us/step - accuracy: 0.7710 - loss: 0.0000e+00 - val_accuracy: 0.7767 - val_loss: 0.0000e+00\n",
      "Epoch 99/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 342us/step - accuracy: 0.7702 - loss: 0.0000e+00 - val_accuracy: 0.7767 - val_loss: 0.0000e+00\n",
      "Epoch 100/100\n",
      "\u001b[1m910/910\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 395us/step - accuracy: 0.7706 - loss: 0.0000e+00 - val_accuracy: 0.7767 - val_loss: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x30ad75410>"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit model\n",
    "num_epochs = 100\n",
    "\n",
    "nn_model.fit(X_train_scaled, y_train,\n",
    "          epochs=num_epochs,\n",
    "          batch_size=100,\n",
    "          validation_split=0.2,     # This 'validation_split' is telling the neural network to keep 20% of the data to validate its score on the training set... this is to help AVOID OVERFITTING. \n",
    "          shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1251/1251 - 0s - 241us/step - accuracy: 0.7745 - loss: 0.0000e+00\n",
      "Loss: 0.0, Accuracy: 0.7745112776756287\n"
     ]
    }
   ],
   "source": [
    "# Show model loss and accuracy\n",
    "\n",
    "# Evaluate the model loss and accuracy metrics using the evaluate method and the test data\n",
    "model_loss, model_accuracy = nn_model.evaluate(X_test_scaled, y_test, verbose=2)\n",
    "\n",
    "# Display the evaluation results\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1251/1251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 220us/step\n",
      "\u001b[1m3553/3553\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 201us/step\n"
     ]
    }
   ],
   "source": [
    "# Predict values using testing data\n",
    "nn_test_predictions = nn_model.predict(X_test_scaled)\n",
    "nn_train_predictions = nn_model.predict(X_train_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.01881538],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [1.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ]], dtype=float32)"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_test_predictions[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Evaluate the model using a classification report\n",
    "# from sklearn.metrics import classification_report\n",
    "# training_report = classification_report(nn_train_predictions, nn_test_predictions)\n",
    "# print(training_report)\n",
    "\n",
    "# # Evaluate the model's ability to predict the trading signal for the testing data using a classification report\n",
    "# training_report = classification_report(y_test, testing_signal_predictions)\n",
    "# print(training_report)\n",
    "\n",
    "# # Save model history for further manipulation\n",
    "# model_history = model.history.model_history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Deployment (Hypothetical)\n",
    "# while True:\n",
    "#     current_data = your_trading_api.get_real_time_data()\n",
    "#     current_data_processed = preprocess_data(current_data)\n",
    "#     prediction = model.predict(current_data_processed)\n",
    "#     if prediction > some_threshold:\n",
    "#         your_trading_api.execute_trade()\n",
    "\n",
    "# # Placeholder Functions\n",
    "# def combine_data(historical, news):\n",
    "#     # Combine and return data\n",
    "#     pass\n",
    "\n",
    "# def split_data(data):\n",
    "#     # Split and return data\n",
    "#     pass\n",
    "\n",
    "# def backtest_strategy(model, data):\n",
    "#     # Implement backtesting logic\n",
    "#     pass\n",
    "\n",
    "# def preprocess_data(data):\n",
    "#     # Data preprocessing steps\n",
    "#     pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
